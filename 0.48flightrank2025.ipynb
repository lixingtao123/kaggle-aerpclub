{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c270c2bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T05:50:05.462715Z",
     "iopub.status.busy": "2025-07-04T05:50:05.461771Z",
     "iopub.status.idle": "2025-07-04T05:50:05.482449Z",
     "shell.execute_reply": "2025-07-04T05:50:05.477013Z",
     "shell.execute_reply.started": "2025-07-04T05:50:05.462691Z"
    },
    "papermill": {
     "duration": 0.006238,
     "end_time": "2025-07-04T12:45:19.809106",
     "exception": false,
     "start_time": "2025-07-04T12:45:19.802868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# AeroClub RecSys 2025 - XGBoost Ranking Baseline\n",
    "\n",
    "This notebook implements an improved ranking approach using XGBoost for the AeroClub recommendation challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e46e185",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T12:45:19.821019Z",
     "iopub.status.busy": "2025-07-04T12:45:19.820703Z",
     "iopub.status.idle": "2025-07-04T12:45:23.627600Z",
     "shell.execute_reply": "2025-07-04T12:45:23.625909Z"
    },
    "papermill": {
     "duration": 3.815526,
     "end_time": "2025-07-04T12:45:23.629996",
     "exception": false,
     "start_time": "2025-07-04T12:45:19.814470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from typing import Tuple, Dict, List\n",
    "import time\n",
    "\n",
    "# 忽略警告\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置pandas显示选项\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9622fa66",
   "metadata": {
    "papermill": {
     "duration": 0.006457,
     "end_time": "2025-07-04T12:45:23.643008",
     "exception": false,
     "start_time": "2025-07-04T12:45:23.636551",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae8add5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T12:45:23.655870Z",
     "iopub.status.busy": "2025-07-04T12:45:23.655321Z",
     "iopub.status.idle": "2025-07-04T12:45:23.661188Z",
     "shell.execute_reply": "2025-07-04T12:45:23.660030Z"
    },
    "papermill": {
     "duration": 0.014321,
     "end_time": "2025-07-04T12:45:23.663030",
     "exception": false,
     "start_time": "2025-07-04T12:45:23.648709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "TRAIN_SAMPLE_FRAC = 1.00 # Sample 50% of data for faster iteration\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Initialize Kaggle API\n",
    "# api = KaggleApi()\n",
    "# api.authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb2a912",
   "metadata": {
    "papermill": {
     "duration": 0.005316,
     "end_time": "2025-07-04T12:45:23.674313",
     "exception": false,
     "start_time": "2025-07-04T12:45:23.668997",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52115d83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T12:45:23.687452Z",
     "iopub.status.busy": "2025-07-04T12:45:23.686480Z"
    },
    "papermill": {
     "duration": 49.140846,
     "end_time": "2025-07-04T12:46:12.820540",
     "exception": false,
     "start_time": "2025-07-04T12:45:23.679694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load parquet files\n",
    "train = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/train.parquet')\n",
    "test = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae1993a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T05:51:10.721601Z",
     "iopub.status.busy": "2025-07-04T05:51:10.721318Z",
     "iopub.status.idle": "2025-07-04T05:51:12.136875Z",
     "shell.execute_reply": "2025-07-04T05:51:12.130632Z",
     "shell.execute_reply.started": "2025-07-04T05:51:10.721576Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Train shape: {train.shape}, Test shape: {test.shape}\")\n",
    "print(f\"Unique ranker_ids in train: {train['ranker_id'].nunique():,}\")\n",
    "print(f\"Selected rate: {train['selected'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b54a2b6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Data Sampling & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f957a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T05:51:12.138444Z",
     "iopub.status.busy": "2025-07-04T05:51:12.138179Z",
     "iopub.status.idle": "2025-07-04T05:51:12.151054Z",
     "shell.execute_reply": "2025-07-04T05:51:12.145085Z",
     "shell.execute_reply.started": "2025-07-04T05:51:12.138418Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample by ranker_id to keep groups intact\n",
    "if TRAIN_SAMPLE_FRAC < 1.0:\n",
    "    unique_rankers = train['ranker_id'].unique()\n",
    "    n_sample = int(len(unique_rankers) * TRAIN_SAMPLE_FRAC)\n",
    "    sampled_rankers = np.random.RandomState(RANDOM_STATE).choice(\n",
    "        unique_rankers, size=n_sample, replace=False\n",
    "    )\n",
    "    train = train[train['ranker_id'].isin(sampled_rankers)]\n",
    "    print(f\"Sampled train to {len(train):,} rows ({train['ranker_id'].nunique():,} groups)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2642764",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T05:51:12.154323Z",
     "iopub.status.busy": "2025-07-04T05:51:12.154062Z",
     "iopub.status.idle": "2025-07-04T05:51:12.738974Z",
     "shell.execute_reply": "2025-07-04T05:51:12.734485Z",
     "shell.execute_reply.started": "2025-07-04T05:51:12.154296Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert ranker_id to string for CatBoost\n",
    "train['ranker_id'] = train['ranker_id'].astype(str)\n",
    "test['ranker_id'] = test['ranker_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46784b2b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490ed1e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T05:51:12.741821Z",
     "iopub.status.busy": "2025-07-04T05:51:12.741605Z",
     "iopub.status.idle": "2025-07-04T05:51:12.753449Z",
     "shell.execute_reply": "2025-07-04T05:51:12.747948Z",
     "shell.execute_reply.started": "2025-07-04T05:51:12.741800Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_features = [\n",
    "    'nationality', 'searchRoute', 'corporateTariffCode',\n",
    "    # Leg 0 segments 0-1\n",
    "    'legs0_segments0_aircraft_code', 'legs0_segments0_arrivalTo_airport_city_iata',\n",
    "    'legs0_segments0_arrivalTo_airport_iata', 'legs0_segments0_departureFrom_airport_iata',\n",
    "    'legs0_segments0_marketingCarrier_code', 'legs0_segments0_operatingCarrier_code',\n",
    "    'legs0_segments0_flightNumber',\n",
    "    'legs0_segments1_aircraft_code', 'legs0_segments1_arrivalTo_airport_city_iata',\n",
    "    'legs0_segments1_arrivalTo_airport_iata', 'legs0_segments1_departureFrom_airport_iata',\n",
    "    'legs0_segments1_marketingCarrier_code', 'legs0_segments1_operatingCarrier_code',\n",
    "    'legs0_segments1_flightNumber',\n",
    "    # Leg 1 segments 0-1\n",
    "    'legs1_segments0_aircraft_code', 'legs1_segments0_arrivalTo_airport_city_iata',\n",
    "    'legs1_segments0_arrivalTo_airport_iata', 'legs1_segments0_departureFrom_airport_iata',\n",
    "    'legs1_segments0_marketingCarrier_code', 'legs1_segments0_operatingCarrier_code',\n",
    "    'legs1_segments0_flightNumber',\n",
    "    'legs1_segments1_aircraft_code', 'legs1_segments1_arrivalTo_airport_city_iata',\n",
    "    'legs1_segments1_arrivalTo_airport_iata', 'legs1_segments1_departureFrom_airport_iata',\n",
    "    'legs1_segments1_marketingCarrier_code', 'legs1_segments1_operatingCarrier_code',\n",
    "    'legs1_segments1_flightNumber'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8a5769",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T05:51:12.755790Z",
     "iopub.status.busy": "2025-07-04T05:51:12.755551Z",
     "iopub.status.idle": "2025-07-04T05:51:12.786635Z",
     "shell.execute_reply": "2025-07-04T05:51:12.782171Z",
     "shell.execute_reply.started": "2025-07-04T05:51:12.755767Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: add time profiling\n",
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Return a copy of df enriched with engineered features.\n",
    "    Fixed issues with zero-importance features.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    def hms_to_minutes(s: pd.Series) -> np.ndarray:\n",
    "        \"\"\"Vectorised 'HH:MM:SS' → minutes (seconds ignored).\"\"\"\n",
    "        mask = s.notna()\n",
    "        out = np.zeros(len(s), dtype=float)\n",
    "        if mask.any():\n",
    "            parts = s[mask].astype(str).str.split(':', expand=True)\n",
    "            out[mask] = (\n",
    "                pd.to_numeric(parts[0], errors=\"coerce\").fillna(0) * 60\n",
    "                + pd.to_numeric(parts[1], errors=\"coerce\").fillna(0)\n",
    "            )\n",
    "        return out\n",
    "\n",
    "    # Duration columns\n",
    "    dur_cols = (\n",
    "        [\"legs0_duration\", \"legs1_duration\"]\n",
    "        + [f\"legs{l}_segments{s}_duration\" for l in (0, 1) for s in (0, 1)]\n",
    "    )\n",
    "    for col in dur_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = hms_to_minutes(df[col])\n",
    "\n",
    "    # Feature container\n",
    "    feat = {}\n",
    "\n",
    "    # Price features\n",
    "    feat[\"price_per_tax\"] = df[\"totalPrice\"] / (df[\"taxes\"] + 1)\n",
    "    feat[\"tax_rate\"] = df[\"taxes\"] / (df[\"totalPrice\"] + 1)\n",
    "    feat[\"log_price\"] = np.log1p(df[\"totalPrice\"])\n",
    "\n",
    "    # Duration features\n",
    "    df[\"total_duration\"] = df[\"legs0_duration\"].fillna(0) + df[\"legs1_duration\"].fillna(0)\n",
    "    feat[\"duration_ratio\"] = np.where(\n",
    "        df[\"legs1_duration\"].fillna(0) > 0,\n",
    "        df[\"legs0_duration\"] / (df[\"legs1_duration\"] + 1),\n",
    "        1.0,\n",
    "    )\n",
    "\n",
    "    # Fix segment count features\n",
    "    # Count actual segments based on non-null duration values\n",
    "    for leg in (0, 1):\n",
    "        seg_count = 0\n",
    "        for seg in range(4):  # Check up to 4 segments\n",
    "            col = f\"legs{leg}_segments{seg}_duration\"\n",
    "            if col in df.columns:\n",
    "                seg_count += df[col].notna().astype(int)\n",
    "            else:\n",
    "                break\n",
    "        feat[f\"n_segments_leg{leg}\"] = seg_count\n",
    "    \n",
    "    feat[\"total_segments\"] = feat[\"n_segments_leg0\"] + feat[\"n_segments_leg1\"]\n",
    "\n",
    "    # Fix trip type detection\n",
    "    # is_one_way should be 1 when there's no return leg\n",
    "    feat[\"is_one_way\"] = (\n",
    "        df[\"legs1_duration\"].isna() | \n",
    "        (df[\"legs1_duration\"] == 0) |\n",
    "        df[\"legs1_segments0_departureFrom_airport_iata\"].isna()\n",
    "    ).astype(int)\n",
    "    \n",
    "    feat[\"has_return\"] = (1 - feat[\"is_one_way\"]).astype(int)\n",
    "\n",
    "    # Rank features\n",
    "    grp = df.groupby(\"ranker_id\")\n",
    "    feat[\"price_rank\"] = grp[\"totalPrice\"].rank()\n",
    "    feat[\"price_pct_rank\"] = grp[\"totalPrice\"].rank(pct=True)\n",
    "    feat[\"duration_rank\"] = grp[\"total_duration\"].rank()\n",
    "    feat[\"is_cheapest\"] = (grp[\"totalPrice\"].transform(\"min\") == df[\"totalPrice\"]).astype(int)\n",
    "    feat[\"is_most_expensive\"] = (grp[\"totalPrice\"].transform(\"max\") == df[\"totalPrice\"]).astype(int)\n",
    "    feat[\"price_from_median\"] = grp[\"totalPrice\"].transform(\n",
    "        lambda x: (x - x.median()) / (x.std() + 1)\n",
    "    )\n",
    "\n",
    "    # Frequent-flyer features - only for airlines actually present in data\n",
    "    ff = df[\"frequentFlyer\"].fillna(\"\").astype(str)\n",
    "    feat[\"n_ff_programs\"] = ff.str.count(\"/\") + (ff != \"\")\n",
    "    \n",
    "    # Check which airlines are actually in the data\n",
    "    carrier_cols = [\"legs0_segments0_marketingCarrier_code\", \"legs1_segments0_marketingCarrier_code\"]\n",
    "    present_airlines = set()\n",
    "    for col in carrier_cols:\n",
    "        if col in df.columns:\n",
    "            present_airlines.update(df[col].dropna().unique())\n",
    "    \n",
    "    # Only create ff features for airlines present in data\n",
    "    for al in [\"SU\", \"S7\", \"U6\", \"TK\"]:  # Keep only major Russian/Turkish airlines\n",
    "        if al in present_airlines:\n",
    "            feat[f\"ff_{al}\"] = ff.str.contains(rf\"\\b{al}\\b\").astype(int)\n",
    "    \n",
    "    # Check if FF matches carrier\n",
    "    feat[\"ff_matches_carrier\"] = 0\n",
    "    for al in [\"SU\", \"S7\", \"U6\", \"TK\"]:\n",
    "        if f\"ff_{al}\" in feat and \"legs0_segments0_marketingCarrier_code\" in df.columns:\n",
    "            feat[\"ff_matches_carrier\"] |= (\n",
    "                (feat.get(f\"ff_{al}\", 0) == 1) & \n",
    "                (df[\"legs0_segments0_marketingCarrier_code\"] == al)\n",
    "            ).astype(int)\n",
    "\n",
    "    # Binary flags\n",
    "    feat[\"is_vip_freq\"] = ((df[\"isVip\"] == 1) | (feat[\"n_ff_programs\"] > 0)).astype(int)\n",
    "    feat[\"has_corporate_tariff\"] = (~df[\"corporateTariffCode\"].isna()).astype(int)\n",
    "\n",
    "    # Baggage and fees\n",
    "    feat[\"baggage_total\"] = (\n",
    "        df[\"legs0_segments0_baggageAllowance_quantity\"].fillna(0)\n",
    "        + df[\"legs1_segments0_baggageAllowance_quantity\"].fillna(0)\n",
    "    )\n",
    "    feat[\"has_baggage\"] = (feat[\"baggage_total\"] > 0).astype(int)\n",
    "    feat[\"total_fees\"] = (\n",
    "        df[\"miniRules0_monetaryAmount\"].fillna(0) + df[\"miniRules1_monetaryAmount\"].fillna(0)\n",
    "    )\n",
    "    feat[\"has_fees\"] = (feat[\"total_fees\"] > 0).astype(int)\n",
    "    feat[\"fee_rate\"] = feat[\"total_fees\"] / (df[\"totalPrice\"] + 1)\n",
    "\n",
    "    # Time-of-day features\n",
    "    for col in (\"legs0_departureAt\", \"legs0_arrivalAt\", \"legs1_departureAt\", \"legs1_arrivalAt\"):\n",
    "        if col in df.columns:\n",
    "            dt = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "            feat[f\"{col}_hour\"] = dt.dt.hour.fillna(12)\n",
    "            feat[f\"{col}_weekday\"] = dt.dt.weekday.fillna(0)\n",
    "            h = dt.dt.hour.fillna(12)\n",
    "            feat[f\"{col}_business_time\"] = (((6 <= h) & (h <= 9)) | ((17 <= h) & (h <= 20))).astype(int)\n",
    "\n",
    "    # Fix direct flight detection\n",
    "    feat[\"is_direct_leg0\"] = (feat[\"n_segments_leg0\"] == 1).astype(int)\n",
    "    feat[\"is_direct_leg1\"] = np.where(\n",
    "        feat[\"is_one_way\"] == 1,\n",
    "        0,  # One-way flights don't have leg1\n",
    "        (feat[\"n_segments_leg1\"] == 1).astype(int)\n",
    "    )\n",
    "    feat[\"both_direct\"] = (feat[\"is_direct_leg0\"] & feat[\"is_direct_leg1\"]).astype(int)\n",
    "\n",
    "    # Cheapest direct flight\n",
    "    df[\"_is_direct\"] = feat[\"is_direct_leg0\"] == 1\n",
    "    direct_groups = df[df[\"_is_direct\"]].groupby(\"ranker_id\")[\"totalPrice\"]\n",
    "    if len(direct_groups) > 0:\n",
    "        direct_min_price = direct_groups.min()\n",
    "        feat[\"is_direct_cheapest\"] = (\n",
    "            df[\"_is_direct\"] & \n",
    "            (df[\"totalPrice\"] == df[\"ranker_id\"].map(direct_min_price))\n",
    "        ).astype(int)\n",
    "    else:\n",
    "        feat[\"is_direct_cheapest\"] = 0\n",
    "    df.drop(columns=\"_is_direct\", inplace=True)\n",
    "\n",
    "    # Other features\n",
    "    feat[\"has_access_tp\"] = (df[\"pricingInfo_isAccessTP\"] == 1).astype(int)\n",
    "    feat[\"group_size\"] = df.groupby(\"ranker_id\")[\"Id\"].transform(\"count\")\n",
    "    feat[\"group_size_log\"] = np.log1p(feat[\"group_size\"])\n",
    "    \n",
    "    # Check if major carrier\n",
    "    if \"legs0_segments0_marketingCarrier_code\" in df.columns:\n",
    "        feat[\"is_major_carrier\"] = df[\"legs0_segments0_marketingCarrier_code\"].isin([\"SU\", \"S7\", \"U6\"]).astype(int)\n",
    "    else:\n",
    "        feat[\"is_major_carrier\"] = 0\n",
    "    \n",
    "    # Popular routes\n",
    "    popular_routes = {\"MOWLED/LEDMOW\", \"LEDMOW/MOWLED\", \"MOWLED\", \"LEDMOW\", \"MOWAER/AERMOW\"}\n",
    "    feat[\"is_popular_route\"] = df[\"searchRoute\"].isin(popular_routes).astype(int)\n",
    "    \n",
    "    # Cabin class features\n",
    "    feat[\"avg_cabin_class\"] = df[[\"legs0_segments0_cabinClass\", \"legs1_segments0_cabinClass\"]].mean(axis=1)\n",
    "    feat[\"cabin_class_diff\"] = (\n",
    "        df[\"legs0_segments0_cabinClass\"].fillna(0) - df[\"legs1_segments0_cabinClass\"].fillna(0)\n",
    "    )\n",
    "\n",
    "    # Merge new features\n",
    "    df = pd.concat([df, pd.DataFrame(feat, index=df.index)], axis=1)\n",
    "\n",
    "    # Final NaN handling\n",
    "    for col in df.select_dtypes(include=\"number\").columns:\n",
    "        df[col] = df[col].fillna(0)\n",
    "    for col in df.select_dtypes(include=\"object\").columns:\n",
    "        df[col] = df[col].fillna(\"missing\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1c06e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T05:51:12.789021Z",
     "iopub.status.busy": "2025-07-04T05:51:12.788797Z",
     "iopub.status.idle": "2025-07-04T06:08:03.741912Z",
     "shell.execute_reply": "2025-07-04T06:08:03.735309Z",
     "shell.execute_reply.started": "2025-07-04T05:51:12.788999Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply feature engineering\n",
    "train = create_features(train)\n",
    "test = create_features(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef06787f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2731b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T06:08:03.745070Z",
     "iopub.status.busy": "2025-07-04T06:08:03.744837Z",
     "iopub.status.idle": "2025-07-04T06:08:03.760338Z",
     "shell.execute_reply": "2025-07-04T06:08:03.754156Z",
     "shell.execute_reply.started": "2025-07-04T06:08:03.745047Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Categorical features\n",
    "cat_features = [\n",
    "    'nationality', 'searchRoute', 'corporateTariffCode',\n",
    "    # Leg 0 segments 0-1\n",
    "    'legs0_segments0_aircraft_code', 'legs0_segments0_arrivalTo_airport_city_iata',\n",
    "    'legs0_segments0_arrivalTo_airport_iata', 'legs0_segments0_departureFrom_airport_iata',\n",
    "    'legs0_segments0_marketingCarrier_code', 'legs0_segments0_operatingCarrier_code',\n",
    "    'legs0_segments0_flightNumber',\n",
    "    'legs0_segments1_aircraft_code', 'legs0_segments1_arrivalTo_airport_city_iata',\n",
    "    'legs0_segments1_arrivalTo_airport_iata', 'legs0_segments1_departureFrom_airport_iata',\n",
    "    'legs0_segments1_marketingCarrier_code', 'legs0_segments1_operatingCarrier_code',\n",
    "    'legs0_segments1_flightNumber',\n",
    "    # Leg 1 segments 0-1\n",
    "    'legs1_segments0_aircraft_code', 'legs1_segments0_arrivalTo_airport_city_iata',\n",
    "    'legs1_segments0_arrivalTo_airport_iata', 'legs1_segments0_departureFrom_airport_iata',\n",
    "    'legs1_segments0_marketingCarrier_code', 'legs1_segments0_operatingCarrier_code',\n",
    "    'legs1_segments0_flightNumber',\n",
    "    'legs1_segments1_aircraft_code', 'legs1_segments1_arrivalTo_airport_city_iata',\n",
    "    'legs1_segments1_arrivalTo_airport_iata', 'legs1_segments1_departureFrom_airport_iata',\n",
    "    'legs1_segments1_marketingCarrier_code', 'legs1_segments1_operatingCarrier_code',\n",
    "    'legs1_segments1_flightNumber'\n",
    "]\n",
    "\n",
    "# Columns to exclude (uninformative or problematic)\n",
    "exclude_cols = [\n",
    "    'Id', 'ranker_id', 'selected', 'profileId', 'requestDate',\n",
    "    'legs0_departureAt', 'legs0_arrivalAt', 'legs1_departureAt', 'legs1_arrivalAt',\n",
    "    'miniRules0_percentage', 'miniRules1_percentage',  # >90% missing\n",
    "    'frequentFlyer',  # Already processed\n",
    "    # Exclude constant or near-constant columns\n",
    "    'bySelf', 'pricingInfo_passengerCount',\n",
    "    # Exclude baggageAllowance_weightMeasurementType columns (likely constant)\n",
    "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
    "    'legs0_segments1_baggageAllowance_weightMeasurementType',\n",
    "    'legs1_segments0_baggageAllowance_weightMeasurementType',\n",
    "    'legs1_segments1_baggageAllowance_weightMeasurementType',\n",
    "    # Exclude ff features for airlines not in data\n",
    "    'ff_DP', 'ff_UT', 'ff_EK', 'ff_N4', 'ff_5N', 'ff_LH'\n",
    "]\n",
    "\n",
    "\n",
    "# Exclude segment 2-3 columns (>98% missing)\n",
    "for leg in [0, 1]:\n",
    "    for seg in [2, 3]:\n",
    "        for suffix in ['aircraft_code', 'arrivalTo_airport_city_iata', 'arrivalTo_airport_iata',\n",
    "                      'baggageAllowance_quantity', 'baggageAllowance_weightMeasurementType',\n",
    "                      'cabinClass', 'departureFrom_airport_iata', 'duration', 'flightNumber',\n",
    "                      'marketingCarrier_code', 'operatingCarrier_code', 'seatsAvailable']:\n",
    "            exclude_cols.append(f'legs{leg}_segments{seg}_{suffix}')\n",
    "\n",
    "feature_cols = [col for col in train.columns if col not in exclude_cols]\n",
    "cat_features_final = [col for col in cat_features if col in feature_cols]\n",
    "\n",
    "print(f\"Using {len(feature_cols)} features ({len(cat_features_final)} categorical)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4ceab0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T06:08:03.762156Z",
     "iopub.status.busy": "2025-07-04T06:08:03.761946Z",
     "iopub.status.idle": "2025-07-04T06:08:03.774996Z",
     "shell.execute_reply": "2025-07-04T06:08:03.770555Z",
     "shell.execute_reply.started": "2025-07-04T06:08:03.762135Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 6. Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed41324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T06:08:03.777886Z",
     "iopub.status.busy": "2025-07-04T06:08:03.777677Z",
     "iopub.status.idle": "2025-07-04T06:08:53.091379Z",
     "shell.execute_reply": "2025-07-04T06:08:53.085852Z",
     "shell.execute_reply.started": "2025-07-04T06:08:03.777866Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X_train = train[feature_cols]\n",
    "y_train = train['selected']\n",
    "groups_train = train['ranker_id']\n",
    "\n",
    "X_test = test[feature_cols]\n",
    "groups_test = test['ranker_id']\n",
    "\n",
    "# Group-based split\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_STATE)\n",
    "train_idx, val_idx = next(gss.split(X_train, y_train, groups_train))\n",
    "\n",
    "X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "groups_tr, groups_val = groups_train.iloc[train_idx], groups_train.iloc[val_idx]\n",
    "\n",
    "print(f\"Train: {len(X_tr):,} rows, Val: {len(X_val):,} rows, Test: {len(X_test):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45139159",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e267028c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T06:08:53.094187Z",
     "iopub.status.busy": "2025-07-04T06:08:53.093921Z",
     "iopub.status.idle": "2025-07-04T06:09:14.488671Z",
     "shell.execute_reply": "2025-07-04T06:09:14.483889Z",
     "shell.execute_reply.started": "2025-07-04T06:08:53.094162Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install -U xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f3101b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T06:09:14.494284Z",
     "iopub.status.busy": "2025-07-04T06:09:14.493909Z",
     "iopub.status.idle": "2025-07-04T06:09:16.436317Z",
     "shell.execute_reply": "2025-07-04T06:09:16.430206Z",
     "shell.execute_reply.started": "2025-07-04T06:09:14.494252Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc0190e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T06:09:16.438894Z",
     "iopub.status.busy": "2025-07-04T06:09:16.438637Z",
     "iopub.status.idle": "2025-07-04T06:12:05.020561Z",
     "shell.execute_reply": "2025-07-04T06:12:05.015077Z",
     "shell.execute_reply.started": "2025-07-04T06:09:16.438869Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare data for XGBoost\n",
    "# Convert categorical features to numeric codes for XGBoost\n",
    "X_tr_xgb = X_tr.copy()\n",
    "X_val_xgb = X_val.copy()\n",
    "X_test_xgb = X_test.copy()\n",
    "\n",
    "# Label encode categorical features\n",
    "for col in cat_features_final:\n",
    "    if col in X_tr_xgb.columns:\n",
    "        # Create a mapping from train data\n",
    "        unique_vals = pd.concat([X_tr_xgb[col], X_val_xgb[col], X_test_xgb[col]]).unique()\n",
    "        mapping = {val: idx for idx, val in enumerate(unique_vals)}\n",
    "        \n",
    "        X_tr_xgb[col] = X_tr_xgb[col].map(mapping).fillna(-1).astype(int)\n",
    "        X_val_xgb[col] = X_val_xgb[col].map(mapping).fillna(-1).astype(int)\n",
    "        X_test_xgb[col] = X_test_xgb[col].map(mapping).fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc32bc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T06:12:05.023123Z",
     "iopub.status.busy": "2025-07-04T06:12:05.022867Z",
     "iopub.status.idle": "2025-07-04T06:35:04.764949Z",
     "shell.execute_reply": "2025-07-04T06:35:04.760080Z",
     "shell.execute_reply.started": "2025-07-04T06:12:05.023099Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create group sizes for XGBoost\n",
    "group_sizes_tr = pd.DataFrame(groups_tr).groupby('ranker_id').size().values\n",
    "group_sizes_val = pd.DataFrame(groups_val).groupby('ranker_id').size().values\n",
    "\n",
    "# Create XGBoost DMatrix\n",
    "dtrain = xgb.DMatrix(X_tr_xgb, label=y_tr, group=group_sizes_tr)\n",
    "dval = xgb.DMatrix(X_val_xgb, label=y_val, group=group_sizes_val)\n",
    "\n",
    "# XGBoost parameters\n",
    "xgb_params = {\n",
    "    'objective': 'rank:pairwise',\n",
    "    'eval_metric': 'ndcg@3',\n",
    "    'max_depth': 9,\n",
    "    'min_child_weight': 8,\n",
    "    'subsample': 0.85,\n",
    "    'colsample_bytree': 0.85,\n",
    "    'lambda': 8.0,\n",
    "    'alpha':2.0,\n",
    "    'learning_rate': 0.04,\n",
    "    'seed': RANDOM_STATE,\n",
    "    'n_jobs': -1,\n",
    "    'tree_method': 'hist',\n",
    "    'max_bin': 512\n",
    "}\n",
    "\n",
    "# Train XGBoost model\n",
    "print(\"Training XGBoost model...\")\n",
    "xgb_model = xgb.train(\n",
    "    xgb_params,\n",
    "    dtrain,\n",
    "    num_boost_round=1500,\n",
    "    evals=[(dtrain, 'train'), (dval, 'val')],\n",
    "    early_stopping_rounds=100,\n",
    "    verbose_eval=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb04f96",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c599816b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T06:35:04.767285Z",
     "iopub.status.busy": "2025-07-04T06:35:04.767038Z",
     "iopub.status.idle": "2025-07-04T06:35:04.781237Z",
     "shell.execute_reply": "2025-07-04T06:35:04.776433Z",
     "shell.execute_reply.started": "2025-07-04T06:35:04.767261Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert scores to probabilities using sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x / 10))\n",
    "\n",
    "# HitRate@3 calculation\n",
    "def calculate_hitrate_at_k(df, k=3):\n",
    "    \"\"\"Calculate HitRate@k for groups with >10 options\"\"\"\n",
    "    hits = []\n",
    "    for ranker_id, group in df.groupby('ranker_id'):\n",
    "        if len(group) > 10:\n",
    "            top_k = group.nlargest(k, 'pred')\n",
    "            hit = (top_k['selected'] == 1).any()\n",
    "            hits.append(hit)\n",
    "    return np.mean(hits) if hits else 0.0\n",
    "\n",
    "def evaluate_model(y_true, y_pred, groups, model_name=\"Model\"):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    df = pd.DataFrame({\n",
    "        'ranker_id': groups,\n",
    "        'pred': y_pred,\n",
    "        'selected': y_true\n",
    "    })\n",
    "    \n",
    "    # Get top prediction per group\n",
    "    top_preds = df.loc[df.groupby('ranker_id')['pred'].idxmax()]\n",
    "    top_preds['prob'] = sigmoid(top_preds['pred'])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    logloss = log_loss(top_preds['selected'], top_preds['prob'])\n",
    "    hitrate_at_3 = calculate_hitrate_at_k(df, k=3)\n",
    "    accuracy = (top_preds['selected'] == 1).mean()\n",
    "    \n",
    "    print(f\"{model_name} Validation Metrics:\")\n",
    "    print(f\"HitRate@3 (groups >10): {hitrate_at_3:.4f}\")\n",
    "    print(f\"LogLoss:                {logloss:.4f}\")\n",
    "    print(f\"Top-1 Accuracy:         {accuracy:.4f}\")\n",
    "    \n",
    "    return df, hitrate_at_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df60338",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T06:35:04.783867Z",
     "iopub.status.busy": "2025-07-04T06:35:04.783642Z",
     "iopub.status.idle": "2025-07-04T06:35:32.099848Z",
     "shell.execute_reply": "2025-07-04T06:35:32.095478Z",
     "shell.execute_reply.started": "2025-07-04T06:35:04.783844Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate XGBoost\n",
    "xgb_val_preds = xgb_model.predict(dval)\n",
    "xgb_val_df, xgb_hr3 = evaluate_model(y_val, xgb_val_preds, groups_val, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8a701c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T06:35:32.102443Z",
     "iopub.status.busy": "2025-07-04T06:35:32.102168Z",
     "iopub.status.idle": "2025-07-04T06:35:32.140735Z",
     "shell.execute_reply": "2025-07-04T06:35:32.135507Z",
     "shell.execute_reply.started": "2025-07-04T06:35:32.102415Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get XGBoost feature importance\n",
    "xgb_importance = xgb_model.get_score(importance_type='gain')\n",
    "\n",
    "# XGBoost уже возвращает словарь с именами фич, просто конвертируем в DataFrame\n",
    "xgb_importance_df = pd.DataFrame([\n",
    "    {'feature': k, 'xgb_importance': v} \n",
    "    for k, v in xgb_importance.items()\n",
    "]).sort_values('xgb_importance', ascending=False)\n",
    "\n",
    "print(xgb_importance_df.iloc[:30].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953ac6e5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 9. Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5838ecd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T06:35:32.143242Z",
     "iopub.status.busy": "2025-07-04T06:35:32.142992Z",
     "iopub.status.idle": "2025-07-04T06:36:03.773398Z",
     "shell.execute_reply": "2025-07-04T06:36:03.769726Z",
     "shell.execute_reply.started": "2025-07-04T06:35:32.143219Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate predictions for test set with XGBoost\n",
    "group_sizes_test = test.groupby('ranker_id').size().values\n",
    "dtest = xgb.DMatrix(X_test_xgb, group=group_sizes_test)\n",
    "xgb_test_preds = xgb_model.predict(dtest)\n",
    "\n",
    "submission_xgb = test[['Id', 'ranker_id']].copy()\n",
    "submission_xgb['pred_score'] = xgb_test_preds\n",
    "submission_xgb['selected'] = submission_xgb.groupby('ranker_id')['pred_score'].rank(\n",
    "    ascending=False, method='first'\n",
    ").astype(int)\n",
    "\n",
    "# Save submissions\n",
    "submission_xgb[['Id', 'ranker_id', 'selected']].to_csv('submission.csv', index=False)\n",
    "\n",
    "print(f\"XGBoost submission saved. Shape: {submission_xgb.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e11d248",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submit to Competition with API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3c47dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T06:36:03.777300Z",
     "iopub.status.busy": "2025-07-04T06:36:03.777061Z",
     "iopub.status.idle": "2025-07-04T06:36:03.787852Z",
     "shell.execute_reply": "2025-07-04T06:36:03.781904Z",
     "shell.execute_reply.started": "2025-07-04T06:36:03.777276Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Submit to competition\n",
    "# api.competition_submit(\n",
    "#     file_name=\"submission.parquet\", \n",
    "#     competition=\"aeroclub-recsys-2025\", \n",
    "#     message=\"CatBoost Ranking Baseline\"\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12733338,
     "sourceId": 105399,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31042,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 60.387273,
   "end_time": "2025-07-04T12:46:13.827756",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-04T12:45:13.440483",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
