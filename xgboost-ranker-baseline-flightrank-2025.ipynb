{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75bcfaf7",
   "metadata": {
    "papermill": {
     "duration": 0.007252,
     "end_time": "2025-06-25T01:26:11.066756",
     "exception": false,
     "start_time": "2025-06-25T01:26:11.059504",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# AeroClub RecSys 2025 - XGBoost Ranking Baseline\n",
    "\n",
    "This notebook implements an improved ranking approach using XGBoost for the AeroClub recommendation challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57d7c740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T01:26:11.080351Z",
     "iopub.status.busy": "2025-06-25T01:26:11.080113Z",
     "iopub.status.idle": "2025-06-25T01:26:18.391592Z",
     "shell.execute_reply": "2025-06-25T01:26:18.385320Z"
    },
    "papermill": {
     "duration": 7.323478,
     "end_time": "2025-06-25T01:26:18.395314",
     "exception": false,
     "start_time": "2025-06-25T01:26:11.071836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "# from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# # Set display options for better readability\n",
    "# pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923df211",
   "metadata": {
    "papermill": {
     "duration": 0.005703,
     "end_time": "2025-06-25T01:26:18.406989",
     "exception": false,
     "start_time": "2025-06-25T01:26:18.401286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74c83cf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T01:26:18.421828Z",
     "iopub.status.busy": "2025-06-25T01:26:18.421445Z",
     "iopub.status.idle": "2025-06-25T01:26:18.431975Z",
     "shell.execute_reply": "2025-06-25T01:26:18.427367Z"
    },
    "papermill": {
     "duration": 0.022234,
     "end_time": "2025-06-25T01:26:18.434781",
     "exception": false,
     "start_time": "2025-06-25T01:26:18.412547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "TRAIN_SAMPLE_FRAC = 0.5  # Sample 50% of data for faster iteration\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Initialize Kaggle API\n",
    "# api = KaggleApi()\n",
    "# api.authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79344dc7",
   "metadata": {
    "papermill": {
     "duration": 0.005467,
     "end_time": "2025-06-25T01:26:18.445475",
     "exception": false,
     "start_time": "2025-06-25T01:26:18.440008",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eda3b019",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T01:26:18.460768Z",
     "iopub.status.busy": "2025-06-25T01:26:18.460512Z",
     "iopub.status.idle": "2025-06-25T01:26:49.800618Z",
     "shell.execute_reply": "2025-06-25T01:26:49.794839Z"
    },
    "papermill": {
     "duration": 31.351328,
     "end_time": "2025-06-25T01:26:49.803212",
     "exception": false,
     "start_time": "2025-06-25T01:26:18.451884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load parquet files\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43maeroclub-recsys-2025/train.parquet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m test = pd.read_parquet(\u001b[33m'\u001b[39m\u001b[33maeroclub-recsys-2025/test.parquet\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Lib\\site-packages\\pandas\\io\\parquet.py:651\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    498\u001b[39m \u001b[38;5;129m@doc\u001b[39m(storage_options=_shared_docs[\u001b[33m\"\u001b[39m\u001b[33mstorage_options\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    499\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_parquet\u001b[39m(\n\u001b[32m    500\u001b[39m     path: FilePath | ReadBuffer[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    508\u001b[39m     **kwargs,\n\u001b[32m    509\u001b[39m ) -> DataFrame:\n\u001b[32m    510\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    511\u001b[39m \u001b[33;03m    Load a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[32m    512\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    648\u001b[39m \u001b[33;03m    1    4    9\u001b[39;00m\n\u001b[32m    649\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m651\u001b[39m     impl = \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    653\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m use_nullable_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default:\n\u001b[32m    654\u001b[39m         msg = (\n\u001b[32m    655\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe argument \u001b[39m\u001b[33m'\u001b[39m\u001b[33muse_nullable_dtypes\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is deprecated and will be removed \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    656\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33min a future version.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    657\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Lib\\site-packages\\pandas\\io\\parquet.py:67\u001b[39m, in \u001b[36mget_engine\u001b[39m\u001b[34m(engine)\u001b[39m\n\u001b[32m     64\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     65\u001b[39m             error_msgs += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m - \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(err)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     68\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnable to find a usable engine; \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     69\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtried using: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfastparquet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA suitable version of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     71\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpyarrow or fastparquet is required for parquet \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     72\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msupport.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     73\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTrying to import the above resulted in these errors:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_msgs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     75\u001b[39m     )\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m PyArrowImpl()\n",
      "\u001b[31mImportError\u001b[39m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "# Load parquet files\n",
    "train = pd.read_parquet('aeroclub-recsys-2025/train.parquet')\n",
    "test = pd.read_parquet('aeroclub-recsys-2025/test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acf516c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T01:26:49.817861Z",
     "iopub.status.busy": "2025-06-25T01:26:49.817611Z",
     "iopub.status.idle": "2025-06-25T01:26:51.252224Z",
     "shell.execute_reply": "2025-06-25T01:26:51.248635Z"
    },
    "papermill": {
     "duration": 1.446901,
     "end_time": "2025-06-25T01:26:51.255813",
     "exception": false,
     "start_time": "2025-06-25T01:26:49.808912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (18145372, 126), Test shape: (6897776, 125)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique ranker_ids in train: 105,539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected rate: 0.006\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train shape: {train.shape}, Test shape: {test.shape}\")\n",
    "print(f\"Unique ranker_ids in train: {train['ranker_id'].nunique():,}\")\n",
    "print(f\"Selected rate: {train['selected'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66167c6f",
   "metadata": {
    "papermill": {
     "duration": 0.00552,
     "end_time": "2025-06-25T01:26:51.267042",
     "exception": false,
     "start_time": "2025-06-25T01:26:51.261522",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Data Sampling & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2502265",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T01:26:51.281321Z",
     "iopub.status.busy": "2025-06-25T01:26:51.281044Z",
     "iopub.status.idle": "2025-06-25T01:27:07.283047Z",
     "shell.execute_reply": "2025-06-25T01:27:07.278835Z"
    },
    "papermill": {
     "duration": 16.013583,
     "end_time": "2025-06-25T01:27:07.285764",
     "exception": false,
     "start_time": "2025-06-25T01:26:51.272181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled train to 9,123,530 rows (52,769 groups)\n"
     ]
    }
   ],
   "source": [
    "# Sample by ranker_id to keep groups intact\n",
    "if TRAIN_SAMPLE_FRAC < 1.0:\n",
    "    unique_rankers = train['ranker_id'].unique()\n",
    "    n_sample = int(len(unique_rankers) * TRAIN_SAMPLE_FRAC)\n",
    "    sampled_rankers = np.random.RandomState(RANDOM_STATE).choice(\n",
    "        unique_rankers, size=n_sample, replace=False\n",
    "    )\n",
    "    train = train[train['ranker_id'].isin(sampled_rankers)]\n",
    "    print(f\"Sampled train to {len(train):,} rows ({train['ranker_id'].nunique():,} groups)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a503930",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T01:27:07.300547Z",
     "iopub.status.busy": "2025-06-25T01:27:07.300268Z",
     "iopub.status.idle": "2025-06-25T01:27:07.686101Z",
     "shell.execute_reply": "2025-06-25T01:27:07.681098Z"
    },
    "papermill": {
     "duration": 0.396618,
     "end_time": "2025-06-25T01:27:07.688564",
     "exception": false,
     "start_time": "2025-06-25T01:27:07.291946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert ranker_id to string for CatBoost\n",
    "train['ranker_id'] = train['ranker_id'].astype(str)\n",
    "test['ranker_id'] = test['ranker_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5419f1",
   "metadata": {
    "papermill": {
     "duration": 0.005347,
     "end_time": "2025-06-25T01:27:07.699169",
     "exception": false,
     "start_time": "2025-06-25T01:27:07.693822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "075fdac5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T01:27:07.712849Z",
     "iopub.status.busy": "2025-06-25T01:27:07.712613Z",
     "iopub.status.idle": "2025-06-25T01:27:07.722423Z",
     "shell.execute_reply": "2025-06-25T01:27:07.718464Z"
    },
    "papermill": {
     "duration": 0.020794,
     "end_time": "2025-06-25T01:27:07.724909",
     "exception": false,
     "start_time": "2025-06-25T01:27:07.704115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_features = [\n",
    "    'nationality', 'searchRoute', 'corporateTariffCode',\n",
    "    # Leg 0 segments 0-1\n",
    "    'legs0_segments0_aircraft_code', 'legs0_segments0_arrivalTo_airport_city_iata',\n",
    "    'legs0_segments0_arrivalTo_airport_iata', 'legs0_segments0_departureFrom_airport_iata',\n",
    "    'legs0_segments0_marketingCarrier_code', 'legs0_segments0_operatingCarrier_code',\n",
    "    'legs0_segments0_flightNumber',\n",
    "    'legs0_segments1_aircraft_code', 'legs0_segments1_arrivalTo_airport_city_iata',\n",
    "    'legs0_segments1_arrivalTo_airport_iata', 'legs0_segments1_departureFrom_airport_iata',\n",
    "    'legs0_segments1_marketingCarrier_code', 'legs0_segments1_operatingCarrier_code',\n",
    "    'legs0_segments1_flightNumber',\n",
    "    # Leg 1 segments 0-1\n",
    "    'legs1_segments0_aircraft_code', 'legs1_segments0_arrivalTo_airport_city_iata',\n",
    "    'legs1_segments0_arrivalTo_airport_iata', 'legs1_segments0_departureFrom_airport_iata',\n",
    "    'legs1_segments0_marketingCarrier_code', 'legs1_segments0_operatingCarrier_code',\n",
    "    'legs1_segments0_flightNumber',\n",
    "    'legs1_segments1_aircraft_code', 'legs1_segments1_arrivalTo_airport_city_iata',\n",
    "    'legs1_segments1_arrivalTo_airport_iata', 'legs1_segments1_departureFrom_airport_iata',\n",
    "    'legs1_segments1_marketingCarrier_code', 'legs1_segments1_operatingCarrier_code',\n",
    "    'legs1_segments1_flightNumber'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2667eccd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T01:27:07.739037Z",
     "iopub.status.busy": "2025-06-25T01:27:07.738802Z",
     "iopub.status.idle": "2025-06-25T01:27:07.771722Z",
     "shell.execute_reply": "2025-06-25T01:27:07.766069Z"
    },
    "papermill": {
     "duration": 0.043881,
     "end_time": "2025-06-25T01:27:07.774006",
     "exception": false,
     "start_time": "2025-06-25T01:27:07.730125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: add time profiling\n",
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Return a copy of df enriched with engineered features.\n",
    "    Fixed issues with zero-importance features.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    def hms_to_minutes(s: pd.Series) -> np.ndarray:\n",
    "        \"\"\"Vectorised 'HH:MM:SS' â†’ minutes (seconds ignored).\"\"\"\n",
    "        mask = s.notna()\n",
    "        out = np.zeros(len(s), dtype=float)\n",
    "        if mask.any():\n",
    "            parts = s[mask].astype(str).str.split(':', expand=True)\n",
    "            out[mask] = (\n",
    "                pd.to_numeric(parts[0], errors=\"coerce\").fillna(0) * 60\n",
    "                + pd.to_numeric(parts[1], errors=\"coerce\").fillna(0)\n",
    "            )\n",
    "        return out\n",
    "\n",
    "    # Duration columns\n",
    "    dur_cols = (\n",
    "        [\"legs0_duration\", \"legs1_duration\"]\n",
    "        + [f\"legs{l}_segments{s}_duration\" for l in (0, 1) for s in (0, 1)]\n",
    "    )\n",
    "    for col in dur_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = hms_to_minutes(df[col])\n",
    "\n",
    "    # Feature container\n",
    "    feat = {}\n",
    "\n",
    "    # Price features\n",
    "    feat[\"price_per_tax\"] = df[\"totalPrice\"] / (df[\"taxes\"] + 1)\n",
    "    feat[\"tax_rate\"] = df[\"taxes\"] / (df[\"totalPrice\"] + 1)\n",
    "    feat[\"log_price\"] = np.log1p(df[\"totalPrice\"])\n",
    "\n",
    "    # Duration features\n",
    "    df[\"total_duration\"] = df[\"legs0_duration\"].fillna(0) + df[\"legs1_duration\"].fillna(0)\n",
    "    feat[\"duration_ratio\"] = np.where(\n",
    "        df[\"legs1_duration\"].fillna(0) > 0,\n",
    "        df[\"legs0_duration\"] / (df[\"legs1_duration\"] + 1),\n",
    "        1.0,\n",
    "    )\n",
    "\n",
    "    # Fix segment count features\n",
    "    # Count actual segments based on non-null duration values\n",
    "    for leg in (0, 1):\n",
    "        seg_count = 0\n",
    "        for seg in range(4):  # Check up to 4 segments\n",
    "            col = f\"legs{leg}_segments{seg}_duration\"\n",
    "            if col in df.columns:\n",
    "                seg_count += df[col].notna().astype(int)\n",
    "            else:\n",
    "                break\n",
    "        feat[f\"n_segments_leg{leg}\"] = seg_count\n",
    "    \n",
    "    feat[\"total_segments\"] = feat[\"n_segments_leg0\"] + feat[\"n_segments_leg1\"]\n",
    "\n",
    "    # Fix trip type detection\n",
    "    # is_one_way should be 1 when there's no return leg\n",
    "    feat[\"is_one_way\"] = (\n",
    "        df[\"legs1_duration\"].isna() | \n",
    "        (df[\"legs1_duration\"] == 0) |\n",
    "        df[\"legs1_segments0_departureFrom_airport_iata\"].isna()\n",
    "    ).astype(int)\n",
    "    \n",
    "    feat[\"has_return\"] = (1 - feat[\"is_one_way\"]).astype(int)\n",
    "\n",
    "    # Rank features\n",
    "    grp = df.groupby(\"ranker_id\")\n",
    "    feat[\"price_rank\"] = grp[\"totalPrice\"].rank()\n",
    "    feat[\"price_pct_rank\"] = grp[\"totalPrice\"].rank(pct=True)\n",
    "    feat[\"duration_rank\"] = grp[\"total_duration\"].rank()\n",
    "    feat[\"is_cheapest\"] = (grp[\"totalPrice\"].transform(\"min\") == df[\"totalPrice\"]).astype(int)\n",
    "    feat[\"is_most_expensive\"] = (grp[\"totalPrice\"].transform(\"max\") == df[\"totalPrice\"]).astype(int)\n",
    "    feat[\"price_from_median\"] = grp[\"totalPrice\"].transform(\n",
    "        lambda x: (x - x.median()) / (x.std() + 1)\n",
    "    )\n",
    "\n",
    "    # Frequent-flyer features - only for airlines actually present in data\n",
    "    ff = df[\"frequentFlyer\"].fillna(\"\").astype(str)\n",
    "    feat[\"n_ff_programs\"] = ff.str.count(\"/\") + (ff != \"\")\n",
    "    \n",
    "    # Check which airlines are actually in the data\n",
    "    carrier_cols = [\"legs0_segments0_marketingCarrier_code\", \"legs1_segments0_marketingCarrier_code\"]\n",
    "    present_airlines = set()\n",
    "    for col in carrier_cols:\n",
    "        if col in df.columns:\n",
    "            present_airlines.update(df[col].dropna().unique())\n",
    "    \n",
    "    # Only create ff features for airlines present in data\n",
    "    for al in [\"SU\", \"S7\", \"U6\", \"TK\"]:  # Keep only major Russian/Turkish airlines\n",
    "        if al in present_airlines:\n",
    "            feat[f\"ff_{al}\"] = ff.str.contains(rf\"\\b{al}\\b\").astype(int)\n",
    "    \n",
    "    # Check if FF matches carrier\n",
    "    feat[\"ff_matches_carrier\"] = 0\n",
    "    for al in [\"SU\", \"S7\", \"U6\", \"TK\"]:\n",
    "        if f\"ff_{al}\" in feat and \"legs0_segments0_marketingCarrier_code\" in df.columns:\n",
    "            feat[\"ff_matches_carrier\"] |= (\n",
    "                (feat.get(f\"ff_{al}\", 0) == 1) & \n",
    "                (df[\"legs0_segments0_marketingCarrier_code\"] == al)\n",
    "            ).astype(int)\n",
    "\n",
    "    # Binary flags\n",
    "    feat[\"is_vip_freq\"] = ((df[\"isVip\"] == 1) | (feat[\"n_ff_programs\"] > 0)).astype(int)\n",
    "    feat[\"has_corporate_tariff\"] = (~df[\"corporateTariffCode\"].isna()).astype(int)\n",
    "\n",
    "    # Baggage and fees\n",
    "    feat[\"baggage_total\"] = (\n",
    "        df[\"legs0_segments0_baggageAllowance_quantity\"].fillna(0)\n",
    "        + df[\"legs1_segments0_baggageAllowance_quantity\"].fillna(0)\n",
    "    )\n",
    "    feat[\"has_baggage\"] = (feat[\"baggage_total\"] > 0).astype(int)\n",
    "    feat[\"total_fees\"] = (\n",
    "        df[\"miniRules0_monetaryAmount\"].fillna(0) + df[\"miniRules1_monetaryAmount\"].fillna(0)\n",
    "    )\n",
    "    feat[\"has_fees\"] = (feat[\"total_fees\"] > 0).astype(int)\n",
    "    feat[\"fee_rate\"] = feat[\"total_fees\"] / (df[\"totalPrice\"] + 1)\n",
    "\n",
    "    # Time-of-day features\n",
    "    for col in (\"legs0_departureAt\", \"legs0_arrivalAt\", \"legs1_departureAt\", \"legs1_arrivalAt\"):\n",
    "        if col in df.columns:\n",
    "            dt = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "            feat[f\"{col}_hour\"] = dt.dt.hour.fillna(12)\n",
    "            feat[f\"{col}_weekday\"] = dt.dt.weekday.fillna(0)\n",
    "            h = dt.dt.hour.fillna(12)\n",
    "            feat[f\"{col}_business_time\"] = (((6 <= h) & (h <= 9)) | ((17 <= h) & (h <= 20))).astype(int)\n",
    "\n",
    "    # Fix direct flight detection\n",
    "    feat[\"is_direct_leg0\"] = (feat[\"n_segments_leg0\"] == 1).astype(int)\n",
    "    feat[\"is_direct_leg1\"] = np.where(\n",
    "        feat[\"is_one_way\"] == 1,\n",
    "        0,  # One-way flights don't have leg1\n",
    "        (feat[\"n_segments_leg1\"] == 1).astype(int)\n",
    "    )\n",
    "    feat[\"both_direct\"] = (feat[\"is_direct_leg0\"] & feat[\"is_direct_leg1\"]).astype(int)\n",
    "\n",
    "    # Cheapest direct flight\n",
    "    df[\"_is_direct\"] = feat[\"is_direct_leg0\"] == 1\n",
    "    direct_groups = df[df[\"_is_direct\"]].groupby(\"ranker_id\")[\"totalPrice\"]\n",
    "    if len(direct_groups) > 0:\n",
    "        direct_min_price = direct_groups.min()\n",
    "        feat[\"is_direct_cheapest\"] = (\n",
    "            df[\"_is_direct\"] & \n",
    "            (df[\"totalPrice\"] == df[\"ranker_id\"].map(direct_min_price))\n",
    "        ).astype(int)\n",
    "    else:\n",
    "        feat[\"is_direct_cheapest\"] = 0\n",
    "    df.drop(columns=\"_is_direct\", inplace=True)\n",
    "\n",
    "    # Other features\n",
    "    feat[\"has_access_tp\"] = (df[\"pricingInfo_isAccessTP\"] == 1).astype(int)\n",
    "    feat[\"group_size\"] = df.groupby(\"ranker_id\")[\"Id\"].transform(\"count\")\n",
    "    feat[\"group_size_log\"] = np.log1p(feat[\"group_size\"])\n",
    "    \n",
    "    # Check if major carrier\n",
    "    if \"legs0_segments0_marketingCarrier_code\" in df.columns:\n",
    "        feat[\"is_major_carrier\"] = df[\"legs0_segments0_marketingCarrier_code\"].isin([\"SU\", \"S7\", \"U6\"]).astype(int)\n",
    "    else:\n",
    "        feat[\"is_major_carrier\"] = 0\n",
    "    \n",
    "    # Popular routes\n",
    "    popular_routes = {\"MOWLED/LEDMOW\", \"LEDMOW/MOWLED\", \"MOWLED\", \"LEDMOW\", \"MOWAER/AERMOW\"}\n",
    "    feat[\"is_popular_route\"] = df[\"searchRoute\"].isin(popular_routes).astype(int)\n",
    "    \n",
    "    # Cabin class features\n",
    "    feat[\"avg_cabin_class\"] = df[[\"legs0_segments0_cabinClass\", \"legs1_segments0_cabinClass\"]].mean(axis=1)\n",
    "    feat[\"cabin_class_diff\"] = (\n",
    "        df[\"legs0_segments0_cabinClass\"].fillna(0) - df[\"legs1_segments0_cabinClass\"].fillna(0)\n",
    "    )\n",
    "\n",
    "    # Merge new features\n",
    "    df = pd.concat([df, pd.DataFrame(feat, index=df.index)], axis=1)\n",
    "\n",
    "    # Final NaN handling\n",
    "    for col in df.select_dtypes(include=\"number\").columns:\n",
    "        df[col] = df[col].fillna(0)\n",
    "    for col in df.select_dtypes(include=\"object\").columns:\n",
    "        df[col] = df[col].fillna(\"missing\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66a4e9eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T01:27:07.787286Z",
     "iopub.status.busy": "2025-06-25T01:27:07.787048Z",
     "iopub.status.idle": "2025-06-25T01:37:59.392313Z",
     "shell.execute_reply": "2025-06-25T01:37:59.387592Z"
    },
    "papermill": {
     "duration": 651.615568,
     "end_time": "2025-06-25T01:37:59.394883",
     "exception": false,
     "start_time": "2025-06-25T01:27:07.779315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply feature engineering\n",
    "train = create_features(train)\n",
    "test = create_features(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4b7291",
   "metadata": {
    "papermill": {
     "duration": 0.005133,
     "end_time": "2025-06-25T01:37:59.406011",
     "exception": false,
     "start_time": "2025-06-25T01:37:59.400878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4929a43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T01:37:59.420229Z",
     "iopub.status.busy": "2025-06-25T01:37:59.419993Z",
     "iopub.status.idle": "2025-06-25T01:37:59.433570Z",
     "shell.execute_reply": "2025-06-25T01:37:59.429352Z"
    },
    "papermill": {
     "duration": 0.024608,
     "end_time": "2025-06-25T01:37:59.435988",
     "exception": false,
     "start_time": "2025-06-25T01:37:59.411380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 112 features (31 categorical)\n"
     ]
    }
   ],
   "source": [
    "# Categorical features\n",
    "cat_features = [\n",
    "    'nationality', 'searchRoute', 'corporateTariffCode',\n",
    "    # Leg 0 segments 0-1\n",
    "    'legs0_segments0_aircraft_code', 'legs0_segments0_arrivalTo_airport_city_iata',\n",
    "    'legs0_segments0_arrivalTo_airport_iata', 'legs0_segments0_departureFrom_airport_iata',\n",
    "    'legs0_segments0_marketingCarrier_code', 'legs0_segments0_operatingCarrier_code',\n",
    "    'legs0_segments0_flightNumber',\n",
    "    'legs0_segments1_aircraft_code', 'legs0_segments1_arrivalTo_airport_city_iata',\n",
    "    'legs0_segments1_arrivalTo_airport_iata', 'legs0_segments1_departureFrom_airport_iata',\n",
    "    'legs0_segments1_marketingCarrier_code', 'legs0_segments1_operatingCarrier_code',\n",
    "    'legs0_segments1_flightNumber',\n",
    "    # Leg 1 segments 0-1\n",
    "    'legs1_segments0_aircraft_code', 'legs1_segments0_arrivalTo_airport_city_iata',\n",
    "    'legs1_segments0_arrivalTo_airport_iata', 'legs1_segments0_departureFrom_airport_iata',\n",
    "    'legs1_segments0_marketingCarrier_code', 'legs1_segments0_operatingCarrier_code',\n",
    "    'legs1_segments0_flightNumber',\n",
    "    'legs1_segments1_aircraft_code', 'legs1_segments1_arrivalTo_airport_city_iata',\n",
    "    'legs1_segments1_arrivalTo_airport_iata', 'legs1_segments1_departureFrom_airport_iata',\n",
    "    'legs1_segments1_marketingCarrier_code', 'legs1_segments1_operatingCarrier_code',\n",
    "    'legs1_segments1_flightNumber'\n",
    "]\n",
    "\n",
    "# Columns to exclude (uninformative or problematic)\n",
    "exclude_cols = [\n",
    "    'Id', 'ranker_id', 'selected', 'profileId', 'requestDate',\n",
    "    'legs0_departureAt', 'legs0_arrivalAt', 'legs1_departureAt', 'legs1_arrivalAt',\n",
    "    'miniRules0_percentage', 'miniRules1_percentage',  # >90% missing\n",
    "    'frequentFlyer',  # Already processed\n",
    "    # Exclude constant or near-constant columns\n",
    "    'bySelf', 'pricingInfo_passengerCount',\n",
    "    # Exclude baggageAllowance_weightMeasurementType columns (likely constant)\n",
    "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
    "    'legs0_segments1_baggageAllowance_weightMeasurementType',\n",
    "    'legs1_segments0_baggageAllowance_weightMeasurementType',\n",
    "    'legs1_segments1_baggageAllowance_weightMeasurementType',\n",
    "    # Exclude ff features for airlines not in data\n",
    "    'ff_DP', 'ff_UT', 'ff_EK', 'ff_N4', 'ff_5N', 'ff_LH'\n",
    "]\n",
    "\n",
    "\n",
    "# Exclude segment 2-3 columns (>98% missing)\n",
    "for leg in [0, 1]:\n",
    "    for seg in [2, 3]:\n",
    "        for suffix in ['aircraft_code', 'arrivalTo_airport_city_iata', 'arrivalTo_airport_iata',\n",
    "                      'baggageAllowance_quantity', 'baggageAllowance_weightMeasurementType',\n",
    "                      'cabinClass', 'departureFrom_airport_iata', 'duration', 'flightNumber',\n",
    "                      'marketingCarrier_code', 'operatingCarrier_code', 'seatsAvailable']:\n",
    "            exclude_cols.append(f'legs{leg}_segments{seg}_{suffix}')\n",
    "\n",
    "feature_cols = [col for col in train.columns if col not in exclude_cols]\n",
    "cat_features_final = [col for col in cat_features if col in feature_cols]\n",
    "\n",
    "print(f\"Using {len(feature_cols)} features ({len(cat_features_final)} categorical)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440731d9",
   "metadata": {
    "papermill": {
     "duration": 0.004859,
     "end_time": "2025-06-25T01:37:59.446107",
     "exception": false,
     "start_time": "2025-06-25T01:37:59.441248",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45ee26dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T01:37:59.459837Z",
     "iopub.status.busy": "2025-06-25T01:37:59.459632Z",
     "iopub.status.idle": "2025-06-25T01:38:26.438505Z",
     "shell.execute_reply": "2025-06-25T01:38:26.433967Z"
    },
    "papermill": {
     "duration": 26.989996,
     "end_time": "2025-06-25T01:38:26.441438",
     "exception": false,
     "start_time": "2025-06-25T01:37:59.451442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 7,292,940 rows, Val: 1,830,590 rows, Test: 6,897,776 rows\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "X_train = train[feature_cols]\n",
    "y_train = train['selected']\n",
    "groups_train = train['ranker_id']\n",
    "\n",
    "X_test = test[feature_cols]\n",
    "groups_test = test['ranker_id']\n",
    "\n",
    "# Group-based split\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_STATE)\n",
    "train_idx, val_idx = next(gss.split(X_train, y_train, groups_train))\n",
    "\n",
    "X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "groups_tr, groups_val = groups_train.iloc[train_idx], groups_train.iloc[val_idx]\n",
    "\n",
    "print(f\"Train: {len(X_tr):,} rows, Val: {len(X_val):,} rows, Test: {len(X_test):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e56cb6",
   "metadata": {
    "papermill": {
     "duration": 0.005452,
     "end_time": "2025-06-25T01:38:26.452397",
     "exception": false,
     "start_time": "2025-06-25T01:38:26.446945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e673fada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T01:38:26.466166Z",
     "iopub.status.busy": "2025-06-25T01:38:26.465938Z",
     "iopub.status.idle": "2025-06-25T01:38:49.005707Z",
     "shell.execute_reply": "2025-06-25T01:38:49.000161Z"
    },
    "papermill": {
     "duration": 22.551508,
     "end_time": "2025-06-25T01:38:49.008926",
     "exception": false,
     "start_time": "2025-06-25T01:38:26.457418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install -U xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfe50add",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T01:38:49.026078Z",
     "iopub.status.busy": "2025-06-25T01:38:49.025795Z",
     "iopub.status.idle": "2025-06-25T01:38:50.959357Z",
     "shell.execute_reply": "2025-06-25T01:38:50.955123Z"
    },
    "papermill": {
     "duration": 1.946102,
     "end_time": "2025-06-25T01:38:50.961794",
     "exception": false,
     "start_time": "2025-06-25T01:38:49.015692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3675c22e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T01:38:50.976470Z",
     "iopub.status.busy": "2025-06-25T01:38:50.976208Z",
     "iopub.status.idle": "2025-06-25T01:40:30.032435Z",
     "shell.execute_reply": "2025-06-25T01:40:30.027465Z"
    },
    "papermill": {
     "duration": 99.067152,
     "end_time": "2025-06-25T01:40:30.034906",
     "exception": false,
     "start_time": "2025-06-25T01:38:50.967754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare data for XGBoost\n",
    "# Convert categorical features to numeric codes for XGBoost\n",
    "X_tr_xgb = X_tr.copy()\n",
    "X_val_xgb = X_val.copy()\n",
    "X_test_xgb = X_test.copy()\n",
    "\n",
    "# Label encode categorical features\n",
    "for col in cat_features_final:\n",
    "    if col in X_tr_xgb.columns:\n",
    "        # Create a mapping from train data\n",
    "        unique_vals = pd.concat([X_tr_xgb[col], X_val_xgb[col], X_test_xgb[col]]).unique()\n",
    "        mapping = {val: idx for idx, val in enumerate(unique_vals)}\n",
    "        \n",
    "        X_tr_xgb[col] = X_tr_xgb[col].map(mapping).fillna(-1).astype(int)\n",
    "        X_val_xgb[col] = X_val_xgb[col].map(mapping).fillna(-1).astype(int)\n",
    "        X_test_xgb[col] = X_test_xgb[col].map(mapping).fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "701bd0ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T01:40:30.049595Z",
     "iopub.status.busy": "2025-06-25T01:40:30.049354Z",
     "iopub.status.idle": "2025-06-25T01:51:42.807112Z",
     "shell.execute_reply": "2025-06-25T01:51:42.799829Z"
    },
    "papermill": {
     "duration": 672.769377,
     "end_time": "2025-06-25T01:51:42.809990",
     "exception": false,
     "start_time": "2025-06-25T01:40:30.040613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-ndcg@3:0.78096\tval-ndcg@3:0.77434"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain-ndcg@3:0.82747\tval-ndcg@3:0.80814"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttrain-ndcg@3:0.83781\tval-ndcg@3:0.81239"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\ttrain-ndcg@3:0.84603\tval-ndcg@3:0.81651"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttrain-ndcg@3:0.85469\tval-ndcg@3:0.81706"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250]\ttrain-ndcg@3:0.86304\tval-ndcg@3:0.81836"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\ttrain-ndcg@3:0.86988\tval-ndcg@3:0.82033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[350]\ttrain-ndcg@3:0.87568\tval-ndcg@3:0.82167"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttrain-ndcg@3:0.88061\tval-ndcg@3:0.82274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[450]\ttrain-ndcg@3:0.88505\tval-ndcg@3:0.82347"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttrain-ndcg@3:0.88959\tval-ndcg@3:0.82489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[550]\ttrain-ndcg@3:0.89300\tval-ndcg@3:0.82564"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\ttrain-ndcg@3:0.89647\tval-ndcg@3:0.82663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[650]\ttrain-ndcg@3:0.90063\tval-ndcg@3:0.82746"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700]\ttrain-ndcg@3:0.90394\tval-ndcg@3:0.82798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[750]\ttrain-ndcg@3:0.90739\tval-ndcg@3:0.82919"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[800]\ttrain-ndcg@3:0.91099\tval-ndcg@3:0.82939"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[850]\ttrain-ndcg@3:0.91405\tval-ndcg@3:0.82969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[900]\ttrain-ndcg@3:0.91753\tval-ndcg@3:0.83013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[950]\ttrain-ndcg@3:0.92086\tval-ndcg@3:0.83114"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain-ndcg@3:0.92364\tval-ndcg@3:0.83156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1050]\ttrain-ndcg@3:0.92673\tval-ndcg@3:0.83177"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1100]\ttrain-ndcg@3:0.92973\tval-ndcg@3:0.83172"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1150]\ttrain-ndcg@3:0.93264\tval-ndcg@3:0.83230"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200]\ttrain-ndcg@3:0.93521\tval-ndcg@3:0.83256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1250]\ttrain-ndcg@3:0.93756\tval-ndcg@3:0.83305"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1300]\ttrain-ndcg@3:0.93980\tval-ndcg@3:0.83342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1350]\ttrain-ndcg@3:0.94175\tval-ndcg@3:0.83398"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1400]\ttrain-ndcg@3:0.94386\tval-ndcg@3:0.83396"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1450]\ttrain-ndcg@3:0.94577\tval-ndcg@3:0.83423"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1499]\ttrain-ndcg@3:0.94737\tval-ndcg@3:0.83487\n"
     ]
    }
   ],
   "source": [
    "# Create group sizes for XGBoost\n",
    "group_sizes_tr = pd.DataFrame(groups_tr).groupby('ranker_id').size().values\n",
    "group_sizes_val = pd.DataFrame(groups_val).groupby('ranker_id').size().values\n",
    "\n",
    "# Create XGBoost DMatrix\n",
    "dtrain = xgb.DMatrix(X_tr_xgb, label=y_tr, group=group_sizes_tr)\n",
    "dval = xgb.DMatrix(X_val_xgb, label=y_val, group=group_sizes_val)\n",
    "\n",
    "# XGBoost parameters\n",
    "xgb_params = {\n",
    "    'objective': 'rank:pairwise',\n",
    "    'eval_metric': 'ndcg@3',\n",
    "    'max_depth': 8,\n",
    "    'min_child_weight': 10,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'lambda': 10.0,\n",
    "    'learning_rate': 0.05,\n",
    "    'seed': RANDOM_STATE,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Train XGBoost model\n",
    "print(\"Training XGBoost model...\")\n",
    "xgb_model = xgb.train(\n",
    "    xgb_params,\n",
    "    dtrain,\n",
    "    num_boost_round=1500,\n",
    "    evals=[(dtrain, 'train'), (dval, 'val')],\n",
    "    early_stopping_rounds=100,\n",
    "    verbose_eval=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3a8e4a",
   "metadata": {
    "papermill": {
     "duration": 0.007834,
     "end_time": "2025-06-25T01:51:42.826969",
     "exception": false,
     "start_time": "2025-06-25T01:51:42.819135",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "077e1265",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T01:51:42.846605Z",
     "iopub.status.busy": "2025-06-25T01:51:42.846285Z",
     "iopub.status.idle": "2025-06-25T01:51:42.861070Z",
     "shell.execute_reply": "2025-06-25T01:51:42.856643Z"
    },
    "papermill": {
     "duration": 0.029034,
     "end_time": "2025-06-25T01:51:42.863830",
     "exception": false,
     "start_time": "2025-06-25T01:51:42.834796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert scores to probabilities using sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x / 10))\n",
    "\n",
    "# HitRate@3 calculation\n",
    "def calculate_hitrate_at_k(df, k=3):\n",
    "    \"\"\"Calculate HitRate@k for groups with >10 options\"\"\"\n",
    "    hits = []\n",
    "    for ranker_id, group in df.groupby('ranker_id'):\n",
    "        if len(group) > 10:\n",
    "            top_k = group.nlargest(k, 'pred')\n",
    "            hit = (top_k['selected'] == 1).any()\n",
    "            hits.append(hit)\n",
    "    return np.mean(hits) if hits else 0.0\n",
    "\n",
    "def evaluate_model(y_true, y_pred, groups, model_name=\"Model\"):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    df = pd.DataFrame({\n",
    "        'ranker_id': groups,\n",
    "        'pred': y_pred,\n",
    "        'selected': y_true\n",
    "    })\n",
    "    \n",
    "    # Get top prediction per group\n",
    "    top_preds = df.loc[df.groupby('ranker_id')['pred'].idxmax()]\n",
    "    top_preds['prob'] = sigmoid(top_preds['pred'])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    logloss = log_loss(top_preds['selected'], top_preds['prob'])\n",
    "    hitrate_at_3 = calculate_hitrate_at_k(df, k=3)\n",
    "    accuracy = (top_preds['selected'] == 1).mean()\n",
    "    \n",
    "    print(f\"{model_name} Validation Metrics:\")\n",
    "    print(f\"HitRate@3 (groups >10): {hitrate_at_3:.4f}\")\n",
    "    print(f\"LogLoss:                {logloss:.4f}\")\n",
    "    print(f\"Top-1 Accuracy:         {accuracy:.4f}\")\n",
    "    \n",
    "    return df, hitrate_at_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7849558f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T01:51:42.882685Z",
     "iopub.status.busy": "2025-06-25T01:51:42.882469Z",
     "iopub.status.idle": "2025-06-25T01:51:55.746781Z",
     "shell.execute_reply": "2025-06-25T01:51:55.741027Z"
    },
    "papermill": {
     "duration": 12.877539,
     "end_time": "2025-06-25T01:51:55.749036",
     "exception": false,
     "start_time": "2025-06-25T01:51:42.871497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Validation Metrics:\n",
      "HitRate@3 (groups >10): 0.5042\n",
      "LogLoss:                0.6871\n",
      "Top-1 Accuracy:         0.3520\n"
     ]
    }
   ],
   "source": [
    "# Evaluate XGBoost\n",
    "xgb_val_preds = xgb_model.predict(dval)\n",
    "xgb_val_df, xgb_hr3 = evaluate_model(y_val, xgb_val_preds, groups_val, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1295186",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T01:51:55.769221Z",
     "iopub.status.busy": "2025-06-25T01:51:55.768965Z",
     "iopub.status.idle": "2025-06-25T01:51:55.797515Z",
     "shell.execute_reply": "2025-06-25T01:51:55.792373Z"
    },
    "papermill": {
     "duration": 0.042356,
     "end_time": "2025-06-25T01:51:55.799855",
     "exception": false,
     "start_time": "2025-06-25T01:51:55.757499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         feature  xgb_importance\n",
      "102                             is_popular_route       45.019257\n",
      "67                                    price_rank       23.592730\n",
      "18   legs0_segments1_arrivalTo_airport_city_iata       19.792063\n",
      "9      legs0_segments0_baggageAllowance_quantity       16.547651\n",
      "10                    legs0_segments0_cabinClass       14.647137\n",
      "53                     miniRules1_monetaryAmount       14.383418\n",
      "48         legs1_segments1_marketingCarrier_code       13.401310\n",
      "103                              avg_cabin_class       13.284999\n",
      "22    legs0_segments1_departureFrom_airport_iata       12.149506\n",
      "69                                 duration_rank       11.658153\n",
      "101                             is_major_carrier       11.405441\n",
      "98                                 has_access_tp       11.266839\n",
      "40                 legs1_segments1_aircraft_code       11.097654\n",
      "4                                          isVip       10.994371\n",
      "17                 legs0_segments1_aircraft_code       10.973896\n",
      "100                               group_size_log       10.700415\n",
      "47                  legs1_segments1_flightNumber       10.508951\n",
      "45    legs1_segments1_departureFrom_airport_iata       10.374735\n",
      "23                      legs0_segments1_duration        9.940314\n",
      "99                                    group_size        9.928096\n",
      "55                        pricingInfo_isAccessTP        9.865734\n",
      "19        legs0_segments1_arrivalTo_airport_iata        8.798176\n",
      "85                                      fee_rate        8.753469\n",
      "5                                 legs0_duration        8.614936\n",
      "3                                     isAccess3D        8.178680\n",
      "70                                   is_cheapest        8.176052\n",
      "41   legs1_segments1_arrivalTo_airport_city_iata        8.013260\n",
      "80                          has_corporate_tariff        7.906375\n",
      "82                                   has_baggage        7.883056\n",
      "20     legs0_segments1_baggageAllowance_quantity        7.548995\n"
     ]
    }
   ],
   "source": [
    "# Get XGBoost feature importance\n",
    "xgb_importance = xgb_model.get_score(importance_type='gain')\n",
    "\n",
    "# XGBoost ÑƒÐ¶Ðµ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ð¸Ð¼ÐµÐ½Ð°Ð¼Ð¸ Ñ„Ð¸Ñ‡, Ð¿Ñ€Ð¾ÑÑ‚Ð¾ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð² DataFrame\n",
    "xgb_importance_df = pd.DataFrame([\n",
    "    {'feature': k, 'xgb_importance': v} \n",
    "    for k, v in xgb_importance.items()\n",
    "]).sort_values('xgb_importance', ascending=False)\n",
    "\n",
    "print(xgb_importance_df.iloc[:30].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64002ee9",
   "metadata": {
    "papermill": {
     "duration": 0.008791,
     "end_time": "2025-06-25T01:51:55.817006",
     "exception": false,
     "start_time": "2025-06-25T01:51:55.808215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 9. Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00ae95cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T01:51:55.838470Z",
     "iopub.status.busy": "2025-06-25T01:51:55.838193Z",
     "iopub.status.idle": "2025-06-25T01:52:25.696182Z",
     "shell.execute_reply": "2025-06-25T01:52:25.689317Z"
    },
    "papermill": {
     "duration": 29.873108,
     "end_time": "2025-06-25T01:52:25.698596",
     "exception": false,
     "start_time": "2025-06-25T01:51:55.825488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost submission saved. Shape: (6897776, 4)\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for test set with XGBoost\n",
    "group_sizes_test = test.groupby('ranker_id').size().values\n",
    "dtest = xgb.DMatrix(X_test_xgb, group=group_sizes_test)\n",
    "xgb_test_preds = xgb_model.predict(dtest)\n",
    "\n",
    "submission_xgb = test[['Id', 'ranker_id']].copy()\n",
    "submission_xgb['pred_score'] = xgb_test_preds\n",
    "submission_xgb['selected'] = submission_xgb.groupby('ranker_id')['pred_score'].rank(\n",
    "    ascending=False, method='first'\n",
    ").astype(int)\n",
    "\n",
    "# Save submissions\n",
    "submission_xgb[['Id', 'ranker_id', 'selected']].to_csv('submission.csv', index=False)\n",
    "\n",
    "print(f\"XGBoost submission saved. Shape: {submission_xgb.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c8cba2",
   "metadata": {
    "papermill": {
     "duration": 0.008595,
     "end_time": "2025-06-25T01:52:25.715356",
     "exception": false,
     "start_time": "2025-06-25T01:52:25.706761",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submit to Competition with API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4eb5bd64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T01:52:25.735187Z",
     "iopub.status.busy": "2025-06-25T01:52:25.734930Z",
     "iopub.status.idle": "2025-06-25T01:52:25.744234Z",
     "shell.execute_reply": "2025-06-25T01:52:25.739693Z"
    },
    "papermill": {
     "duration": 0.023586,
     "end_time": "2025-06-25T01:52:25.746730",
     "exception": false,
     "start_time": "2025-06-25T01:52:25.723144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Submit to competition\n",
    "# api.competition_submit(\n",
    "#     file_name=\"submission.parquet\", \n",
    "#     competition=\"aeroclub-recsys-2025\", \n",
    "#     message=\"CatBoost Ranking Baseline\"\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "databundleVersionId": 12733338,
     "sourceId": 105399,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31042,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1588.72045,
   "end_time": "2025-06-25T01:52:36.493077",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-25T01:26:07.772627",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
