{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T03:10:33.087718Z",
     "iopub.status.busy": "2025-07-03T03:10:33.087351Z",
     "iopub.status.idle": "2025-07-03T03:10:33.094681Z",
     "shell.execute_reply": "2025-07-03T03:10:33.093453Z",
     "shell.execute_reply.started": "2025-07-03T03:10:33.087692Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 超级内存节省模式\n",
      "📊 采样比例: 50.0%\n"
     ]
    }
   ],
   "source": [
    "# ========== 超级内存节省版本 ==========\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 🔥 极端配置\n",
    "TRAIN_SAMPLE_FRAC = 0.5  # 🔥 只用50%数据\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# 🔥 设置pandas内存优化\n",
    "pd.set_option('mode.copy_on_write', True)\n",
    "\n",
    "print(f\"🔥 超级内存节省模式\")\n",
    "print(f\"📊 采样比例: {TRAIN_SAMPLE_FRAC*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T03:10:33.096677Z",
     "iopub.status.busy": "2025-07-03T03:10:33.096287Z",
     "iopub.status.idle": "2025-07-03T03:10:55.050322Z",
     "shell.execute_reply": "2025-07-03T03:10:55.049394Z",
     "shell.execute_reply.started": "2025-07-03T03:10:33.096628Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 分块加载数据策略\n",
      "📥 第一步：只读取ranker_id列...\n",
      "   原始ranker_id数量: 105,539\n",
      "   采样ranker_id数量: 52,769\n",
      "📥 第二步：读取必要列...\n",
      "   采样后训练数据: (9123530, 13)\n",
      "   测试数据: (6897776, 12)\n",
      "✅ 数据加载完成\n",
      "   训练数据: (9123530, 13)\n",
      "   测试数据: (6897776, 12)\n",
      "   内存使用显著减少\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========== 分块加载数据 ==========\n",
    "print(\"🚀 分块加载数据策略\")\n",
    "\n",
    "def load_data_in_chunks():\n",
    "    \"\"\"分块加载并立即采样\"\"\"\n",
    "    \n",
    "    # 🔥 方法1: 先获取ranker_id列表\n",
    "    print(\"📥 第一步：只读取ranker_id列...\")\n",
    "    \n",
    "    # 只读取ranker_id列\n",
    "    train_ids = pd.read_parquet(\n",
    "        '/kaggle/input/aeroclub-recsys-2025/train.parquet', \n",
    "        columns=['ranker_id']\n",
    "    )\n",
    "    \n",
    "    print(f\"   原始ranker_id数量: {train_ids['ranker_id'].nunique():,}\")\n",
    "    \n",
    "    # 🔥 立即采样ranker_id\n",
    "    unique_rankers = train_ids['ranker_id'].unique()\n",
    "    n_sample = int(len(unique_rankers) * TRAIN_SAMPLE_FRAC)\n",
    "    sampled_rankers = np.random.RandomState(RANDOM_STATE).choice(\n",
    "        unique_rankers, size=n_sample, replace=False\n",
    "    )\n",
    "    \n",
    "    print(f\"   采样ranker_id数量: {len(sampled_rankers):,}\")\n",
    "    \n",
    "    # 🔥 删除不需要的数据\n",
    "    del train_ids, unique_rankers\n",
    "    gc.collect()\n",
    "    \n",
    "    # 🔥 第二步：只读取必要的列\n",
    "    print(\"📥 第二步：读取必要列...\")\n",
    "    \n",
    "    # 只读取最基础的列\n",
    "    essential_cols = [\n",
    "        'Id', 'ranker_id', 'selected', 'totalPrice', 'taxes',\n",
    "        'legs0_duration', 'legs1_duration', 'isVip',\n",
    "        'nationality', 'searchRoute',\n",
    "        'legs0_segments0_marketingCarrier_code',\n",
    "        'legs0_segments0_arrivalTo_airport_iata',\n",
    "        'legs0_segments0_departureFrom_airport_iata'\n",
    "    ]\n",
    "    \n",
    "    # 读取训练数据的必要列\n",
    "    train = pd.read_parquet(\n",
    "        '/kaggle/input/aeroclub-recsys-2025/train.parquet',\n",
    "        columns=essential_cols\n",
    "    )\n",
    "    \n",
    "    # 🔥 立即过滤到采样的ranker_id\n",
    "    train = train[train['ranker_id'].isin(sampled_rankers)].copy()\n",
    "    \n",
    "    print(f\"   采样后训练数据: {train.shape}\")\n",
    "    \n",
    "    # 🔥 读取测试数据的对应列\n",
    "    test_cols = [col for col in essential_cols if col != 'selected']\n",
    "    test = pd.read_parquet(\n",
    "        '/kaggle/input/aeroclub-recsys-2025/test.parquet',\n",
    "        columns=test_cols\n",
    "    )\n",
    "    \n",
    "    print(f\"   测试数据: {test.shape}\")\n",
    "    \n",
    "    # 🔥 立即优化数据类型\n",
    "    for col in ['ranker_id', 'nationality', 'searchRoute', \n",
    "                'legs0_segments0_marketingCarrier_code',\n",
    "                'legs0_segments0_arrivalTo_airport_iata', \n",
    "                'legs0_segments0_departureFrom_airport_iata']:\n",
    "        if col in train.columns:\n",
    "            train[col] = train[col].astype('category')\n",
    "        if col in test.columns:\n",
    "            test[col] = test[col].astype('category')\n",
    "    \n",
    "    # 转换数值列为更小的类型\n",
    "    for col in ['totalPrice', 'taxes']:\n",
    "        if col in train.columns:\n",
    "            train[col] = train[col].astype(np.float32)\n",
    "        if col in test.columns:\n",
    "            test[col] = test[col].astype(np.float32)\n",
    "    \n",
    "    for col in ['selected', 'isVip']:\n",
    "        if col in train.columns:\n",
    "            train[col] = train[col].astype(np.int8)\n",
    "        if col in test.columns:\n",
    "            test[col] = test[col].astype(np.int8)\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "# 执行数据加载\n",
    "train, test = load_data_in_chunks()\n",
    "\n",
    "print(f\"✅ 数据加载完成\")\n",
    "print(f\"   训练数据: {train.shape}\")\n",
    "print(f\"   测试数据: {test.shape}\")\n",
    "print(f\"   内存使用显著减少\")\n",
    "\n",
    "# 立即清理\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T03:10:55.051535Z",
     "iopub.status.busy": "2025-07-03T03:10:55.051226Z",
     "iopub.status.idle": "2025-07-03T03:10:59.648513Z",
     "shell.execute_reply": "2025-07-03T03:10:59.647501Z",
     "shell.execute_reply.started": "2025-07-03T03:10:55.051508Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 终极简化特征工程\n",
      "🔧 训练数据...\n",
      "   处理数据: (9123530, 13)\n",
      "   计算价格排名...\n",
      "   标记最便宜选项...\n",
      "   ✅ 完成，新增4个特征\n",
      "🔧 测试数据...\n",
      "   处理数据: (6897776, 12)\n",
      "   计算价格排名...\n",
      "   标记最便宜选项...\n",
      "   ✅ 完成，新增4个特征\n",
      "✅ 特征工程完成！\n",
      "   训练数据: (9123530, 17)\n",
      "   测试数据: (6897776, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========== 终极简化特征工程 ==========\n",
    "print(\"🚀 终极简化特征工程\")\n",
    "\n",
    "def ultra_simple_features(df):\n",
    "    \"\"\"终极简化 - 0秒完成\"\"\"\n",
    "    \n",
    "    print(f\"   处理数据: {df.shape}\")\n",
    "    \n",
    "    # 🔥 只要最基础的特征，不做任何复杂计算\n",
    "    \n",
    "    # 1. 价格对数\n",
    "    df['log_price'] = np.log1p(df['totalPrice']).astype(np.float32)\n",
    "    \n",
    "    # 2. 税费比例\n",
    "    df['tax_ratio'] = (df['taxes'] / (df['totalPrice'] + 1)).astype(np.float32)\n",
    "    \n",
    "    # 3. 组内价格排名 - 这是最重要的特征\n",
    "    print(\"   计算价格排名...\")\n",
    "    df['price_rank'] = df.groupby('ranker_id')['totalPrice'].rank().astype(np.int16)\n",
    "    \n",
    "    # 4. 是否最便宜\n",
    "    print(\"   标记最便宜选项...\")\n",
    "    price_min = df.groupby('ranker_id')['totalPrice'].transform('min')\n",
    "    df['is_cheapest'] = (df['totalPrice'] == price_min).astype(np.int8)\n",
    "    \n",
    "    print(f\"   ✅ 完成，新增4个特征\")\n",
    "    return df\n",
    "\n",
    "# 🔥 快速应用\n",
    "print(\"🔧 训练数据...\")\n",
    "train = ultra_simple_features(train)\n",
    "\n",
    "print(\"🔧 测试数据...\")\n",
    "test = ultra_simple_features(test)\n",
    "\n",
    "print(f\"✅ 特征工程完成！\")\n",
    "print(f\"   训练数据: {train.shape}\")\n",
    "print(f\"   测试数据: {test.shape}\")\n",
    "\n",
    "# 清理\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T03:10:59.650888Z",
     "iopub.status.busy": "2025-07-03T03:10:59.650517Z",
     "iopub.status.idle": "2025-07-03T03:11:02.620758Z",
     "shell.execute_reply": "2025-07-03T03:11:02.619841Z",
     "shell.execute_reply.started": "2025-07-03T03:10:59.650857Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 快速模型训练\n",
      "📊 使用特征: 11 个\n",
      "   X_train: (9123530, 11)\n",
      "   X_test: (6897776, 11)\n",
      "   分割完成 - Train: 7298824, Val: 1824706\n"
     ]
    }
   ],
   "source": [
    "# ========== 快速模型训练 ==========\n",
    "print(\"🚀 快速模型训练\")\n",
    "\n",
    "# 🔥 只使用最少的特征\n",
    "feature_cols = [\n",
    "    'totalPrice', 'taxes', 'legs0_duration', 'legs1_duration',\n",
    "    'log_price', 'total_duration', 'is_one_way', \n",
    "    'price_rank', 'is_cheapest', 'isVip',\n",
    "    'nationality', 'searchRoute', 'legs0_segments0_marketingCarrier_code'\n",
    "]\n",
    "\n",
    "# 确保特征存在\n",
    "feature_cols = [col for col in feature_cols if col in train.columns and col in test.columns]\n",
    "\n",
    "print(f\"📊 使用特征: {len(feature_cols)} 个\")\n",
    "\n",
    "# 准备数据\n",
    "X_train = train[feature_cols].copy()\n",
    "y_train = train['selected'].copy()\n",
    "groups_train = train['ranker_id'].copy()\n",
    "\n",
    "X_test = test[feature_cols].copy()\n",
    "groups_test = test['ranker_id'].copy()\n",
    "\n",
    "# 🔥 删除原始数据释放内存\n",
    "del train, test\n",
    "gc.collect()\n",
    "\n",
    "print(f\"   X_train: {X_train.shape}\")\n",
    "print(f\"   X_test: {X_test.shape}\")\n",
    "\n",
    "# 🔥 简单验证分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 按照80/20分割，不用GroupShuffleSplit节省内存\n",
    "train_size = int(0.8 * len(X_train))\n",
    "X_tr = X_train[:train_size].copy()\n",
    "X_val = X_train[train_size:].copy()\n",
    "y_tr = y_train[:train_size].copy()\n",
    "y_val = y_train[train_size:].copy()\n",
    "groups_tr = groups_train[:train_size].copy()\n",
    "groups_val = groups_train[train_size:].copy()\n",
    "\n",
    "# 🔥 删除完整训练数据\n",
    "del X_train, y_train, groups_train\n",
    "gc.collect()\n",
    "\n",
    "print(f\"   分割完成 - Train: {len(X_tr)}, Val: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T03:11:02.622171Z",
     "iopub.status.busy": "2025-07-03T03:11:02.621862Z",
     "iopub.status.idle": "2025-07-03T03:12:56.362343Z",
     "shell.execute_reply": "2025-07-03T03:12:56.361163Z",
     "shell.execute_reply.started": "2025-07-03T03:11:02.622145Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 修复数据类型并训练XGBoost\n",
      "🔧 修复数据类型...\n",
      "   修复 legs0_duration 列...\n",
      "   修复 legs1_duration 列...\n",
      "   转换类别列 nationality...\n",
      "   转换类别列 searchRoute...\n",
      "   转换类别列 legs0_segments0_marketingCarrier_code...\n",
      "   ✅ 数据类型修复完成\n",
      "   X_tr形状: (7298824, 11)\n",
      "   数据类型分布: {dtype('float32'): 5, dtype('int32'): 3, dtype('int8'): 2, dtype('int16'): 1}\n",
      "📊 创建组信息...\n",
      "   训练组数: 52769\n",
      "   验证组数: 52769\n",
      "   训练数据总行数: 7298824\n",
      "   组大小总和: 7298824\n",
      "🚀 创建DMatrix...\n",
      "   X_tr数据类型: {dtype('float32'): 5, dtype('int32'): 3, dtype('int8'): 2, dtype('int16'): 1}\n",
      "   是否有object类型: False\n",
      "   ✅ DMatrix创建成功\n",
      "🚀 开始训练...\n",
      "[0]\ttrain-logloss:0.10723\tval-logloss:0.10954\n",
      "[10]\ttrain-logloss:0.02810\tval-logloss:0.03199\n",
      "[20]\ttrain-logloss:0.02545\tval-logloss:0.02951\n",
      "[30]\ttrain-logloss:0.02517\tval-logloss:0.02922\n",
      "[40]\ttrain-logloss:0.02500\tval-logloss:0.02904\n",
      "[49]\ttrain-logloss:0.02489\tval-logloss:0.02890\n",
      "✅ 训练成功完成\n",
      "🎉 XGBoost训练步骤完成\n"
     ]
    }
   ],
   "source": [
    "# ========== 修复数据类型并训练XGBoost ==========\n",
    "print(\"🚀 修复数据类型并训练XGBoost\")\n",
    "\n",
    "# 🔥 首先修复所有数据类型问题\n",
    "def fix_data_types(X_tr, X_val, X_test):\n",
    "    \"\"\"修复所有数据类型问题\"\"\"\n",
    "    print(\"🔧 修复数据类型...\")\n",
    "    \n",
    "    # 🔥 创建副本避免修改原数据\n",
    "    X_tr = X_tr.copy()\n",
    "    X_val = X_val.copy() \n",
    "    X_test = X_test.copy()\n",
    "    \n",
    "    # 处理duration列 - 如果是object，转换为0\n",
    "    for col in ['legs0_duration', 'legs1_duration']:\n",
    "        if col in X_tr.columns:\n",
    "            if X_tr[col].dtype == 'object':\n",
    "                print(f\"   修复 {col} 列...\")\n",
    "                X_tr[col] = pd.to_numeric(X_tr[col], errors='coerce').fillna(0).astype(np.float32)\n",
    "                X_val[col] = pd.to_numeric(X_val[col], errors='coerce').fillna(0).astype(np.float32)\n",
    "                X_test[col] = pd.to_numeric(X_test[col], errors='coerce').fillna(0).astype(np.float32)\n",
    "    \n",
    "    # 🔥 强制转换所有非数值列\n",
    "    for col in X_tr.columns:\n",
    "        if X_tr[col].dtype in ['object', 'category'] or str(X_tr[col].dtype).startswith('string'):\n",
    "            print(f\"   转换类别列 {col}...\")\n",
    "            # 对所有object/category列进行Label Encoding\n",
    "            all_vals = pd.concat([\n",
    "                X_tr[col].astype(str), \n",
    "                X_val[col].astype(str), \n",
    "                X_test[col].astype(str)\n",
    "            ]).unique()\n",
    "            \n",
    "            # 创建映射字典\n",
    "            mapping = {val: i for i, val in enumerate(all_vals)}\n",
    "            \n",
    "            # 应用映射并转换为数值类型\n",
    "            X_tr[col] = X_tr[col].astype(str).map(mapping).fillna(-1).astype(np.int32)\n",
    "            X_val[col] = X_val[col].astype(str).map(mapping).fillna(-1).astype(np.int32)\n",
    "            X_test[col] = X_test[col].astype(str).map(mapping).fillna(-1).astype(np.int32)\n",
    "            \n",
    "        elif X_tr[col].dtype == 'bool':\n",
    "            # 布尔转换为int\n",
    "            X_tr[col] = X_tr[col].astype(np.int8)\n",
    "            X_val[col] = X_val[col].astype(np.int8)\n",
    "            X_test[col] = X_test[col].astype(np.int8)\n",
    "        \n",
    "        # 🔥 确保所有数值列都是float32或int类型\n",
    "        elif X_tr[col].dtype in ['float64']:\n",
    "            X_tr[col] = X_tr[col].astype(np.float32)\n",
    "            X_val[col] = X_val[col].astype(np.float32)\n",
    "            X_test[col] = X_test[col].astype(np.float32)\n",
    "    \n",
    "    # 🔥 最后检查：确保没有object类型的列\n",
    "    for col in X_tr.columns:\n",
    "        if X_tr[col].dtype == 'object':\n",
    "            print(f\"   🚨 发现遗漏的object列: {col}, 强制转换为数值\")\n",
    "            X_tr[col] = pd.to_numeric(X_tr[col], errors='coerce').fillna(0).astype(np.float32)\n",
    "            X_val[col] = pd.to_numeric(X_val[col], errors='coerce').fillna(0).astype(np.float32)\n",
    "            X_test[col] = pd.to_numeric(X_test[col], errors='coerce').fillna(0).astype(np.float32)\n",
    "    \n",
    "    # 填充所有NaN\n",
    "    X_tr = X_tr.fillna(0)\n",
    "    X_val = X_val.fillna(0)\n",
    "    X_test = X_test.fillna(0)\n",
    "    \n",
    "    print(f\"   ✅ 数据类型修复完成\")\n",
    "    print(f\"   X_tr形状: {X_tr.shape}\")\n",
    "    print(f\"   数据类型分布: {X_tr.dtypes.value_counts().to_dict()}\")\n",
    "    \n",
    "    # 🔥 最终验证：检查是否还有非数值类型\n",
    "    non_numeric_cols = []\n",
    "    for col in X_tr.columns:\n",
    "        if not pd.api.types.is_numeric_dtype(X_tr[col]):\n",
    "            non_numeric_cols.append(col)\n",
    "    \n",
    "    if non_numeric_cols:\n",
    "        print(f\"   ⚠️ 警告：仍有非数值列: {non_numeric_cols}\")\n",
    "        # 强制转换剩余的列\n",
    "        for col in non_numeric_cols:\n",
    "            X_tr[col] = pd.to_numeric(X_tr[col], errors='coerce').fillna(0).astype(np.float32)\n",
    "            X_val[col] = pd.to_numeric(X_val[col], errors='coerce').fillna(0).astype(np.float32)\n",
    "            X_test[col] = pd.to_numeric(X_test[col], errors='coerce').fillna(0).astype(np.float32)\n",
    "    \n",
    "    return X_tr, X_val, X_test\n",
    "\n",
    "# 修复数据类型\n",
    "X_tr, X_val, X_test = fix_data_types(X_tr, X_val, X_test)\n",
    "\n",
    "# 🔥 创建简化的组信息\n",
    "print(\"📊 创建组信息...\")\n",
    "\n",
    "# 正确计算组大小\n",
    "def get_group_sizes(groups):\n",
    "    \"\"\"获取正确的组大小\"\"\"\n",
    "    return groups.value_counts().sort_index().values\n",
    "\n",
    "group_sizes_tr = get_group_sizes(groups_tr)\n",
    "group_sizes_val = get_group_sizes(groups_val)\n",
    "\n",
    "print(f\"   训练组数: {len(group_sizes_tr)}\")\n",
    "print(f\"   验证组数: {len(group_sizes_val)}\")\n",
    "print(f\"   训练数据总行数: {len(X_tr)}\")\n",
    "print(f\"   组大小总和: {group_sizes_tr.sum()}\")\n",
    "\n",
    "# 🔥 创建DMatrix\n",
    "print(\"🚀 创建DMatrix...\")\n",
    "try:\n",
    "    # 🔥 第一步：检查数据类型\n",
    "    print(f\"   X_tr数据类型: {X_tr.dtypes.value_counts().to_dict()}\")\n",
    "    print(f\"   是否有object类型: {(X_tr.dtypes == 'object').any()}\")\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_tr, label=y_tr, group=group_sizes_tr)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val, group=group_sizes_val)\n",
    "    print(\"   ✅ DMatrix创建成功\")\n",
    "except Exception as e:\n",
    "    print(f\"   ❌ DMatrix创建失败: {e}\")\n",
    "    print(\"   🔄 尝试启用分类特征支持...\")\n",
    "    \n",
    "    try:\n",
    "        dtrain = xgb.DMatrix(X_tr, label=y_tr, group=group_sizes_tr, enable_categorical=True)\n",
    "        dval = xgb.DMatrix(X_val, label=y_val, group=group_sizes_val, enable_categorical=True)\n",
    "        print(\"   ✅ 启用分类特征的DMatrix创建成功\")\n",
    "    except Exception as e2:\n",
    "        print(f\"   ❌ 启用分类特征也失败: {e2}\")\n",
    "        print(\"   🔄 尝试纯数值方法...\")\n",
    "        \n",
    "        try:\n",
    "            # 🔥 只保留数值列\n",
    "            numeric_cols = X_tr.select_dtypes(include=[np.number]).columns\n",
    "            print(f\"   使用 {len(numeric_cols)} 个数值列\")\n",
    "            \n",
    "            X_tr_numeric = X_tr[numeric_cols].fillna(0).astype(np.float32)\n",
    "            X_val_numeric = X_val[numeric_cols].fillna(0).astype(np.float32)\n",
    "            \n",
    "            dtrain = xgb.DMatrix(X_tr_numeric, label=y_tr, group=group_sizes_tr)\n",
    "            dval = xgb.DMatrix(X_val_numeric, label=y_val, group=group_sizes_val)\n",
    "            print(\"   ✅ 数值列DMatrix创建成功\")\n",
    "            \n",
    "            # 🔥 更新X_test以保持一致\n",
    "            X_test = X_test[numeric_cols].fillna(0).astype(np.float32)\n",
    "            \n",
    "        except Exception as e3:\n",
    "            print(f\"   ❌ 数值列方法也失败: {e3}\")\n",
    "            print(\"   🔄 最后尝试：简化到二分类...\")\n",
    "            \n",
    "            try:\n",
    "                # 🔥 最后方案：放弃ranking，只用二分类\n",
    "                X_tr_simple = X_tr.select_dtypes(include=[np.number]).fillna(0).values.astype(np.float32)\n",
    "                X_val_simple = X_val.select_dtypes(include=[np.number]).fillna(0).values.astype(np.float32)\n",
    "                \n",
    "                dtrain = xgb.DMatrix(X_tr_simple, label=y_tr.values)\n",
    "                dval = xgb.DMatrix(X_val_simple, label=y_val.values)\n",
    "                print(\"   ✅ 简化二分类DMatrix创建成功\")\n",
    "                \n",
    "                # 🔥 更新X_test\n",
    "                X_test = pd.DataFrame(X_test.select_dtypes(include=[np.number]).fillna(0).values.astype(np.float32))\n",
    "                \n",
    "            except Exception as e4:\n",
    "                print(f\"   💥 所有DMatrix创建方法都失败了: {e4}\")\n",
    "                raise RuntimeError(\"无法创建XGBoost DMatrix，请检查数据\")\n",
    "\n",
    "# 🔥 超级简化的XGBoost参数\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # 🔥 改为二分类，更简单\n",
    "    'eval_metric': 'logloss',\n",
    "    'max_depth': 4,  # 🔥 很浅的树\n",
    "    'learning_rate': 0.3,  # 🔥 更高的学习率\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'seed': RANDOM_STATE,\n",
    "    'verbosity': 0,\n",
    "    'n_jobs': 2  # 🔥 限制并行\n",
    "}\n",
    "\n",
    "print(\"🚀 开始训练...\")\n",
    "try:\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=50,  # 🔥 只训练50轮\n",
    "        evals=[(dtrain, 'train'), (dval, 'val')],\n",
    "        early_stopping_rounds=10,\n",
    "        verbose_eval=10\n",
    "    )\n",
    "    print(\"✅ 训练成功完成\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 训练失败: {e}\")\n",
    "    # 如果还是失败，用最简单的参数\n",
    "    print(\"🔄 尝试最简单的训练...\")\n",
    "    model = xgb.train(\n",
    "        {'objective': 'binary:logistic', 'verbosity': 0},\n",
    "        dtrain,\n",
    "        num_boost_round=20\n",
    "    )\n",
    "    print(\"✅ 简化训练完成\")\n",
    "\n",
    "# 🔥 立即清理训练数据释放内存\n",
    "del dtrain, X_tr, y_tr, groups_tr\n",
    "if 'dval' in locals():\n",
    "    del dval\n",
    "gc.collect()\n",
    "\n",
    "print(\"🎉 XGBoost训练步骤完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T03:12:56.363767Z",
     "iopub.status.busy": "2025-07-03T03:12:56.363491Z",
     "iopub.status.idle": "2025-07-03T03:13:18.257853Z",
     "shell.execute_reply": "2025-07-03T03:13:18.256828Z",
     "shell.execute_reply.started": "2025-07-03T03:12:56.363747Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 修复预测并创建提交文件\n",
      "📥 确保有Id列...\n",
      "   ✅ 成功读取 6897776 个Id\n",
      "🔮 生成预测...\n",
      "   创建测试DMatrix（不使用group信息）...\n",
      "   开始预测...\n",
      "   ✅ 生成了 6897776 个预测\n",
      "📊 创建提交文件...\n",
      "   提交数据形状: (6897776, 3)\n",
      "   预测值范围: 0.0000 到 0.9654\n",
      "🏆 计算组内排名...\n",
      "   排名计算完成，范围: 1 到 7022\n",
      "🎉 任务完成！\n",
      "   📁 文件名: ultra_fast_submission.csv\n",
      "   📊 预测数量: 6,897,776\n",
      "   🏆 排名范围: 1 到 7022\n",
      "\n",
      "📈 提交文件统计:\n",
      "   总行数: 6897776\n",
      "   唯一Id数: 6897776\n",
      "   唯一ranker_id数: 45231\n",
      "   排名分布（前10）:\n",
      "     排名1: 45,231 个\n",
      "     排名2: 44,347 个\n",
      "     排名3: 43,120 个\n",
      "     排名4: 41,915 个\n",
      "     排名5: 41,102 个\n",
      "     排名6: 40,615 个\n",
      "     排名7: 39,389 个\n",
      "     排名8: 38,946 个\n",
      "     排名9: 38,282 个\n",
      "     排名10: 37,258 个\n",
      "\n",
      "🔍 验证提交文件:\n",
      "   必需列: ['Id', 'ranker_id', 'selected']\n",
      "   是否有重复Id: False\n",
      "   selected列数据类型: int64\n",
      "   🔥 ranker_id列已包含: True\n",
      "\n",
      "📋 提交文件示例（前5行）:\n",
      "      Id                        ranker_id  selected\n",
      "18144679 c9373e5f772e43d593dd6ad2fa90f67a         1\n",
      "18144680 c9373e5f772e43d593dd6ad2fa90f67a        52\n",
      "18144681 c9373e5f772e43d593dd6ad2fa90f67a       150\n",
      "18144682 c9373e5f772e43d593dd6ad2fa90f67a       154\n",
      "18144683 c9373e5f772e43d593dd6ad2fa90f67a       252\n",
      "\n",
      "🚀 所有步骤完成！文件已保存到: ultra_fast_submission.csv\n",
      "📝 可以直接提交这个CSV文件到Kaggle竞赛\n"
     ]
    }
   ],
   "source": [
    "# ========== 修复预测并创建提交文件 ==========\n",
    "print(\"🚀 修复预测并创建提交文件\")\n",
    "\n",
    "# 🔥 重新读取test的Id列（因为可能丢失了）\n",
    "print(\"📥 确保有Id列...\")\n",
    "try:\n",
    "    test_ids = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/test.parquet', columns=['Id'])\n",
    "    print(f\"   ✅ 成功读取 {len(test_ids)} 个Id\")\n",
    "except Exception as e:\n",
    "    print(f\"   ⚠️ 无法读取Id列，使用索引: {e}\")\n",
    "    test_ids = pd.DataFrame({'Id': range(len(X_test))})\n",
    "\n",
    "# 🔥 生成预测 - 修复group结构问题\n",
    "print(\"🔮 生成预测...\")\n",
    "try:\n",
    "    # 🔥 关键修复：不使用group信息创建测试DMatrix\n",
    "    # 因为我们使用的是binary:logistic，不需要group信息\n",
    "    print(\"   创建测试DMatrix（不使用group信息）...\")\n",
    "    dtest = xgb.DMatrix(X_test)  # 🔥 不传入group参数\n",
    "    \n",
    "    print(\"   开始预测...\")\n",
    "    test_preds = model.predict(dtest)\n",
    "    print(f\"   ✅ 生成了 {len(test_preds)} 个预测\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   ❌ 标准预测失败: {e}\")\n",
    "    print(\"   🔄 尝试更简单的预测方法...\")\n",
    "    \n",
    "    try:\n",
    "        # 🔥 如果还是失败，直接使用numpy数组\n",
    "        test_preds = model.predict(xgb.DMatrix(X_test.values))\n",
    "        print(f\"   ✅ 简化预测成功，生成了 {len(test_preds)} 个预测\")\n",
    "    except Exception as e2:\n",
    "        print(f\"   ❌ 简化预测也失败: {e2}\")\n",
    "        print(\"   ⚠️ 使用随机预测作为后备方案\")\n",
    "        test_preds = np.random.random(len(X_test))\n",
    "\n",
    "# 🔥 创建提交DataFrame\n",
    "print(\"📊 创建提交文件...\")\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_ids['Id'],\n",
    "    'ranker_id': groups_test,\n",
    "    'pred_score': test_preds\n",
    "})\n",
    "\n",
    "print(f\"   提交数据形状: {submission.shape}\")\n",
    "print(f\"   预测值范围: {test_preds.min():.4f} 到 {test_preds.max():.4f}\")\n",
    "\n",
    "# 🔥 计算组内排名\n",
    "print(\"🏆 计算组内排名...\")\n",
    "submission['selected'] = submission.groupby('ranker_id')['pred_score'].rank(\n",
    "    ascending=False, method='first'\n",
    ").astype(int)\n",
    "\n",
    "print(f\"   排名计算完成，范围: 1 到 {submission['selected'].max()}\")\n",
    "\n",
    "# 🔥 保存最终提交文件\n",
    "output_file = 'ultra_fast_submission.csv'\n",
    "# 🔥 修复：包含ranker_id列\n",
    "final_submission = submission[['Id', 'ranker_id', 'selected']]\n",
    "final_submission.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"🎉 任务完成！\")\n",
    "print(f\"   📁 文件名: {output_file}\")\n",
    "print(f\"   📊 预测数量: {len(final_submission):,}\")\n",
    "print(f\"   🏆 排名范围: 1 到 {submission['selected'].max()}\")\n",
    "\n",
    "# 显示一些统计信息\n",
    "print(f\"\\n📈 提交文件统计:\")\n",
    "print(f\"   总行数: {len(final_submission)}\")\n",
    "print(f\"   唯一Id数: {final_submission['Id'].nunique()}\")\n",
    "print(f\"   唯一ranker_id数: {final_submission['ranker_id'].nunique()}\")\n",
    "print(f\"   排名分布（前10）:\")\n",
    "rank_counts = final_submission['selected'].value_counts().head(10)\n",
    "for rank in sorted(rank_counts.index):\n",
    "    count = rank_counts[rank]\n",
    "    print(f\"     排名{rank}: {count:,} 个\")\n",
    "\n",
    "# 🔥 验证提交文件格式\n",
    "print(f\"\\n🔍 验证提交文件:\")\n",
    "print(f\"   必需列: {list(final_submission.columns)}\")\n",
    "print(f\"   是否有重复Id: {final_submission['Id'].duplicated().any()}\")\n",
    "print(f\"   selected列数据类型: {final_submission['selected'].dtype}\")\n",
    "print(f\"   🔥 ranker_id列已包含: {'ranker_id' in final_submission.columns}\")\n",
    "\n",
    "# 🔥 显示提交文件示例\n",
    "print(f\"\\n📋 提交文件示例（前5行）:\")\n",
    "print(final_submission.head().to_string(index=False))\n",
    "\n",
    "# 🔥 最终清理\n",
    "if 'model' in locals():\n",
    "    del model\n",
    "if 'dtest' in locals():\n",
    "    del dtest\n",
    "del X_test, submission, final_submission\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\n🚀 所有步骤完成！文件已保存到: {output_file}\")\n",
    "print(\"📝 可以直接提交这个CSV文件到Kaggle竞赛\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T03:13:18.259173Z",
     "iopub.status.busy": "2025-07-03T03:13:18.258827Z",
     "iopub.status.idle": "2025-07-03T03:13:18.309839Z",
     "shell.execute_reply": "2025-07-03T03:13:18.308678Z",
     "shell.execute_reply.started": "2025-07-03T03:13:18.259144Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 可选: 进一步分析\n",
      "📊 预测分数统计:\n",
      "   最小值: 0.0000\n",
      "   最大值: 0.9654\n",
      "   均值: 0.0073\n",
      "   标准差: 0.0307\n",
      "\n",
      "📏 测试集组大小分布:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'submission' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36/4182050251.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 检查组大小分布\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n📏 测试集组大小分布:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtest_group_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ranker_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   平均组大小: {test_group_sizes.mean():.1f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   组大小范围: {test_group_sizes.min()}-{test_group_sizes.max()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'submission' is not defined"
     ]
    }
   ],
   "source": [
    "# ========== 可选: 进一步分析 ==========\n",
    "print(\"🔍 可选: 进一步分析\")\n",
    "\n",
    "# 预测分数分布\n",
    "print(\"📊 预测分数统计:\")\n",
    "print(f\"   最小值: {test_preds.min():.4f}\")\n",
    "print(f\"   最大值: {test_preds.max():.4f}\")\n",
    "print(f\"   均值: {test_preds.mean():.4f}\")\n",
    "print(f\"   标准差: {test_preds.std():.4f}\")\n",
    "\n",
    "# 检查组大小分布\n",
    "print(f\"\\n📏 测试集组大小分布:\")\n",
    "test_group_sizes = submission.groupby('ranker_id').size()\n",
    "print(f\"   平均组大小: {test_group_sizes.mean():.1f}\")\n",
    "print(f\"   组大小范围: {test_group_sizes.min()}-{test_group_sizes.max()}\")\n",
    "print(f\"   组大小众数: {test_group_sizes.mode().iloc[0]}\")\n",
    "\n",
    "size_dist = test_group_sizes.value_counts().sort_index()\n",
    "print(f\"   组大小分布（前10个）:\")\n",
    "for size in size_dist.head(10).index:\n",
    "    print(f\"     大小{size}: {size_dist[size]:,}组\")\n",
    "\n",
    "# 内存使用情况\n",
    "print(f\"\\n💾 内存清理...\")\n",
    "del train, test, train_features, test_features, X_train, X_test\n",
    "del X_tr, X_val, X_tr_encoded, X_val_encoded, X_test_encoded\n",
    "del dtrain, dval, dtest\n",
    "gc.collect()\n",
    "print(\"✅ 内存清理完成\")\n",
    "\n",
    "print(\"\\n🎉 所有分析完成！\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12733338,
     "sourceId": 105399,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
